---
title: "EVST 496 Tree Giveaway Data"
subtitle: "Cleaning of Tree Giveaway Data of Holyoke, MA and Chelsea, MA"
author: "Eduardo Marin"
date: "`r format(Sys.time())`"
output:
  pdf_document:
    toc: true
  html_document:
    theme: flatly
    code_folding: hide
    fig_width: 8
    fig_height: 7
    fig_caption: true
    toc: true
    toc_float: true
    self_contained: true
editor_options:
  chunk_output_type: console
  markdown:
    wrap: 72
---

# 0. Loading the packages
```{r Loading Packages, message=FALSE, include=FALSE}

# 1. Loading all packages
packs <-c(
            'janitor'    # cleans things up, also pipe-friendly cross-tabulations
           , 'sf'         # for spatial data support
          , 'tidyverse'  # cuz
          # , 'tidylog'    # prints out what was done in dplyr and tidyr
          , 'magrittr'   # for the pipe
          , 'mapview'    # web maps for zooming and panning around
          #, 'beepr'      # makes noise when things are done!
          , 'tictoc'     # timing things.
          , 'raster'
          # , 'doParallel' # does what is says! PARALLEL
          # 'broom.mixed',# tidiers for mixed models AND nlme::gls()
          # , 'lubridate'   # DATES!
          , 'tidycensus' # tidy census package
          , 'tidygeocoder' # geo coding
          , 'leaflet' #creating the interactive mapping elements (more specific)
          , 'shiny'
          , 'leafsync'  # linked maps
          , 'RColorBrewer'
          , 'DT'
          , 'openxlsx'
          , 'mapdeck'
          , 'biscale' #used with ggplot to make bivariate maps
          , 'cowplot' #used to make more aesthetic ggplot visuals
          , 'ggspatial' #creates a basemap for your ggplots
          , 'classInt' #find me breaks without doing manualcalculations
          , 'rgl' #needs for rayshader
          , 'rayshader' #good data viz for 3d bar graphs
          , 'leaflet' #for heatmaps and more unique, customizable maps
          , 'leaflet.extras'
          , 'tidytext'
          , 'scales'
          , 'readxl'
          )     

#2. If the packages in 'packs' are not already installed, install them
if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
install.packages(setdiff(packs, rownames(installed.packages())))
}
vapply(packs, library, character.only = TRUE, logical(1), logical.return = TRUE, quietly = TRUE)

# 3. Items for tidy census
census_api_key('58fc555c77c229747ade7d9fe50e7c71297cf91a', install = TRUE, overwrite = TRUE)
readRenviron("~/.Renviron")
options(tigris_use_cache = TRUE)
```

# 1. Reading the Chelsea, MA and Holyoke, MA Giveaway Data 
```{r Reading the Chelsea, MA & Holyoke, MA data}
# 1. Working with the Chelsea giveaway data
chelsea_giveaways <-
  read_csv("input_data/Chelsea/Tree Giveaways/2017CorrectedChelseaAllTreesComplete.csv")

# 2. Working with the Holyoke giveaway data
holyoke_giveaways <-
  read_csv("input_data/Holyoke/Tree Giveaways/holy_random_clean_fixed.csv") # DL: There appears to be no address information

```

```{r Transforming and messing with the data of Chelsea, MA eval=FALSE, include=FALSE}
#----------------#
# This does not need to be read. It was just some preliminary analysis done to understand the dates and what the data is trying to say
#----------------#

# 1. Checking if there are any duplicates in their IDs
chelsea_giveaways |>
  filter(duplicated(OID_) | duplicated(OID_, fromLast = TRUE))

chelsea_giveaways |> #All the the duplicates appear to be from TreID_1 that are NAs, so most likely, the one we should use is the OID_
  filter(!is.na(TreID_1)) |>
  filter(duplicated(TreID_1) | duplicated(TreID_1, fromLast = TRUE)) |>
  view()

# 2. Looking at unique values of certain categories
### a) Finding more general categories

#DHL here's another way to do that
chelsea_giveaways |>
  # st_drop_geometry() |> # not needed here but from the example I had already
  # select(-id) |>        # same, 
  mutate_if(is.character, as.factor) |> # factorize the characters
  select_if(is.factor) |>               # select the factor
  map(~tabyl(.)) |>                     # cross tabulate them all
  bind_rows(.id = 'var')                # combine and retain

# DATEPLANTE shoudl be a date, not a character or factor



sort(unique(chelsea_giveaways$GGC_PUB)) #GGC_Pub shows public or private
sort(unique(chelsea_giveaways$REPLACE))
sort(unique(chelsea_giveaways$COMMENT))
sort(unique(chelsea_giveaways$Cultivar))
sort(unique(chelsea_giveaways$Deciduous)) # Checks if it is either Decidious or Evergreen
sort(unique(chelsea_giveaways$Broadleaf)) # Checks if it is a Broadleaf or a Conifer
sort(unique(chelsea_giveaways$Native_Sta))
sort(unique(chelsea_giveaways$DBH_dcr)) # DBH measurements, I think
sort(unique(chelsea_giveaways$Hght_dc)) # Tree Height but needs cleaning
sort(unique(chelsea_giveaways$BSp_17))
sort(unique(chelsea_giveaways$Cmmnt_1)) # Comments on planting of the trees (EM: Should be mentioned as a potential bias/issue for the future)
sort(unique(chelsea_giveaways$StTp_17))
sort(unique(chelsea_giveaways$Wth_17))
sort(unique(chelsea_giveaways$Rnd_Smp))
sort(unique(chelsea_giveaways$DBH2H_17))
sort(unique(chelsea_giveaways$DBH1H_17)) #DL: This seems important; unsure what this is trying to measure
sort(unique(chelsea_giveaways$Com_24)) 

### b) Finding for specific years
####—Checking Hght_dc
chelsea_giveaways |>
  dplyr::select(GGC_YEA, Hght_dc) |>
  distinct() |>
  arrange(GGC_YEA, Hght_dc) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(Hght_dc, collapse = ", ")) |>
  print(n = Inf) # Hght_dc Appears to only track from 2021—2023

####—Checking BSp_17
chelsea_giveaways |>
  dplyr::select(GGC_YEA, BSp_17) |>
  distinct() |>
  arrange(GGC_YEA, BSp_17) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(BSp_17, collapse = ", ")) |>
  print(n = Inf) #BSp_17 Appears to only only track from 2014—2016

####—Checking DBH1_17
chelsea_giveaways |>
  dplyr::select(GGC_YEA, DBH1_17) |>
  distinct() |>
  arrange(GGC_YEA, DBH1_17) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(DBH1_17, collapse = ", ")) |>
  print(n = Inf) #DBH1_17 seems to have only be tracked from 2014—2016

####—Checking DBH_dcr
chelsea_giveaways |>
  dplyr::select(GGC_YEA, DBH_dcr) |>
  distinct() |>
  arrange(GGC_YEA, DBH_dcr) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(DBH_dcr, collapse = ", ")) |>
  print(n = Inf) # DBH_dcr seems to have only tracked from 2021—2023

####—Checking LUse_17
chelsea_giveaways |>
  dplyr::select(GGC_YEA, LUse_17) |>
  distinct() |>
  arrange(GGC_YEA, LUse_17) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(LUse_17, collapse = ", ")) |>
  print(n = Inf) # LUse_17 seems to have only be tracked from 2014—2016

####—Checking M_17
chelsea_giveaways |>
  dplyr::select(GGC_YEA, M_17) |>
  distinct() |>
  arrange(GGC_YEA, M_17) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(M_17, collapse = ", ")) |>
  print(n = Inf) # M_17 seems to be survivorship; but it is only tracked from 2014—2016

####—Checking StTp_17
chelsea_giveaways |>
  dplyr::select(GGC_YEA, StTp_17) |>
  distinct() |>
  arrange(GGC_YEA, StTp_17) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(StTp_17, collapse = ", ")) |>
  print(n = Inf) # StTp_17 seems to have only be tracked from 2014—2016

####—Checking V_17
chelsea_giveaways |>
  dplyr::select(GGC_YEA, V_17) |>
  distinct() |>
  arrange(GGC_YEA, V_17) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(V_17, collapse = ", ")) |>
  print(n = Inf) # V_17 seems to have only be tracked from 2014—2016

####—Checking Wth_17
chelsea_giveaways |>
  dplyr::select(GGC_YEA, Wth_17) |>
  distinct() |>
  arrange(GGC_YEA, Wth_17) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(Wth_17, collapse = ", ")) |>
  print(n = Inf) # Wth_17 seems to be width and it has have only been tracked from 2014—2016

####—Checking DBH2H_17
chelsea_giveaways |>
  dplyr::select(GGC_YEA, DBH2H_17) |>
  distinct() |>
  arrange(GGC_YEA, DBH2H_17) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(DBH2H_17, collapse = ", ")) |>
  print(n = Inf) # DBH2H_17 seems to not have anything worthwhile

####—Checking DBH1H_17
chelsea_giveaways |>
  dplyr::select(GGC_YEA, DBH1H_17) |>
  distinct() |>
  arrange(GGC_YEA, DBH1H_17) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(DBH1H_17, collapse = ", ")) |>
  print(n = Inf) # DBH1H_17 seems to not have anything worthwhile

####—Checking StTp_24
chelsea_giveaways |>
  dplyr::select(GGC_YEA, StTp_24) |>
  distinct() |>
  arrange(GGC_YEA, StTp_24) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(StTp_24, collapse = ", ")) |>
  print(n = Inf) # StTp_24 seems to have all years DL: wondering why did they include just the FY BY for the year 2014—2016 separate. 

####—Checking LUse_24
chelsea_giveaways |>
  dplyr::select(GGC_YEA, LUse_24) |>
  distinct() |>
  arrange(GGC_YEA, LUse_24) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(LUse_24, collapse = ", ")) |>
  print(n = Inf) # LUse_24 seems to have all land uses. Again, DL: wondering why did they include the land use for the year 2014—2016 separate.

####—Checking Bsp_24
chelsea_giveaways |>
  dplyr::select(GGC_YEA, Bsp_24) |>
  distinct() |>
  arrange(GGC_YEA, Bsp_24) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(Bsp_24, collapse = ", ")) |>
  print(n = Inf) # Bsp_24 seems to have all the basal sprouts. Seems less comprehensive than before

####—Checking V_24
chelsea_giveaways |>
  dplyr::select(GGC_YEA, V_24) |>
  distinct() |>
  arrange(GGC_YEA, V_24) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(V_24, collapse = ", ")) |>
  print(n = Inf) # V_24 seems to have all the vigor and they are connected to the presentation slide values

####—Checking Con_24
chelsea_giveaways |>
  dplyr::select(GGC_YEA, Con_24) |>
  distinct() |>
  arrange(GGC_YEA, Con_24) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(Con_24, collapse = ", ")) |>
  print(n = Inf) # Con_24 conditions for all years

####—Checking DBH1_24
chelsea_giveaways |>
  dplyr::select(GGC_YEA, DBH1_24) |>
  distinct() |>
  arrange(GGC_YEA, DBH1_24) |>
  group_by(GGC_YEA) |>
  summarise(List = paste(DBH1_24, collapse = ", ")) |>
  print(n = Inf) # DBH1_24 conditions for all years

# DL: Would not do this with the Holyoke, looked at the data and figured it was the same format as the Chelsea #EM: What do you mean?

```

# 2. Cleaning the Chelsea, MA Giveaway Data 
```{r Reading and Cleaning Giveaway Data Chelsea, echo=TRUE, message=FALSE}
# 1. Overview of all the variables (including all of the years surveyed)
chelsea_giveaway_overview <-
  chelsea_giveaways |>
    rename(
      Date_Planted                 = DATEPLANTE
    , Address                      = nw_ddrs
    , Public_Private               = GGC_PUB
    , Comment_General              = COMMENT
    , Cultivar                     = Cultivar
    , Year_Planted                 = GGC_YEA
    , Season_Planted               = GGC_SEA
    , City                         = CITY_GG
    , Family                       = Family
    , Genus                        = Genus
    , Deciduous_Evergreen          = Deciduous 
    , Broadleaf_Conifer            = Broadleaf
    , Species                      = Species
    , Native_Status                = Native_Sta
    # , DBH_2021_2023                = DBH_dcr
    , Height_2017                  = Hght_17 # EM: To do! Needs cleaning
    , Owner_Address_P1             = ADDRESS # Needs double checking here
    , Owner_Address_P2             = OWNERAD # Needs standardization
    , Basal_Sprouts_2017           = BSp_17
    , Comment_Survey_2017          = Cmmnt_1
    , DBH_2017                     = DBH1_17
    , Mortality_Status_2017        = M_17
    , Vigor_2017                   = V_17
    , Land_Use_2017                = LUse_17
    , Site_Type_2017               = StTp_17  
    , Width_2017                   = Wth_17
    , Common_Name                  = CommonName
    , Unique_ID_New                = NewTrID 
    , Site_Type_2024               = StTp_24
    , Land_Use_2024                = LUse_24
    , Basal_Sprouts_2024           = Bsp_24 # Seems to be less comprehensive
    , Vigor_2024                   = V_24
    , Conditions_2024              = Con_24 # Condition for all the years
    , Comment_Survey_2024          = Com_24
    , DBH_2024                     = DBH1_24
    , Height_2024                  = Hgt_24
    , Width_2024                   = Wth_24
    , Date_Surveyed                = D_24
    , Mortality_Status_2024        = M_24
    , Date_Inserted                = CreationDate
    , Author_Inserted              = Creator
    , Date_Edited                  = EditDate
    , Author_Edited                = Editor
    , Easting                      = X
    , Northing                     = Y
  ) 
   
# Removing these columns: 
## TreID_1 — appears to have more NAs and not the real address
## RD_NUM — appears to be the road number
## RD_NUMB — appears to be the road number but less selective
## RD_NAME — appears to be the road name
## RD_SUFF — appears to be the road suffix: ex. Ave, St, etc. 
## DBH2_17 — appears to have only 2015 data that is insufficient compared to DBH1_17
## V_17 — appears to be vigor but the values make no sense (for those reasons, currently not including until #         further information is provided)
## Rnd_Smp — appears to be an abbreviation of random sample; not sure what this could help us in [gives    
#            values of only 0, 1]
## H17_Smp — appears to be maybe an abbreviation for height; not sure if this is important [gives values of
#            only 0, 1]
## DBH2H_17 — appears to only have three values—0, 21, 54; seems useless
## HERO2017 — appears to only have the value of 1, unsure how helpful 
## DBH1H_24 — appears to only be a larger scale x10 of the DBH that we saw earlier
## DBH2_24 — unsure what this is
## DBH2H_24 — unsure what this is

# 2. Selected variables for further analysis
pre_chelsea_giveaway_analysis <- 
  chelsea_giveaway_overview |>
  dplyr::select (
      Unique_ID_New                
    , Address                  
    # , Owner_Address_P1             
    # , Owner_Address_P2             
    , City                         
    , Date_Planted                 
    , Year_Planted                 
    , Season_Planted               
    # , Date_Surveyed                
    # , Date_Inserted                
    # , Author_Inserted              
    # , Date_Edited                  
    # , Author_Edited                
    , Family                       
    , Genus                        
    , Species                      
    , Cultivar                     
    , Common_Name                  
    , Native_Status                
    , Deciduous_Evergreen          
    , Broadleaf_Conifer            
    , Public_Private    
    , Land_Use_2017
    , Land_Use_2024
    , Site_Type_2017  
    , Site_Type_2024     
    , Vigor_2017
    , Vigor_2024     
    , Mortality_Status_2017
    , Mortality_Status_2024
    # , Conditions_2017 This does not seem to eist
    , Conditions_2024         
    , DBH_2017
    , DBH_2024     
    , Height_2017
    , Height_2024    
    , Width_2017
    , Width_2024 
    , Basal_Sprouts_2017
    , Basal_Sprouts_2024      
    , Comment_General              
    , Comment_Survey_2017             
    , Comment_Survey_2024          
    , Easting                      
    , Northing                     
  ) |>
  mutate(Year_Planted = as.character(Year_Planted)) #Need this for the merge


# 3. Getting the lat and long of the variables for further analysis
## a) Transforming into an SF object based off of Massachusetts State Plane, NAD83, feet
pre_chelsea_giveaway_analysis <- 
  pre_chelsea_giveaway_analysis |>
  st_as_sf(coords = c("Easting", "Northing"), crs = 26986, remove = FALSE) |> # remove = FALSE instead of below. Safer
  st_transform(crs = 4326)  #EM: Rename Easting and Northing to Latitude and Longtidue

# ## b) Receiving the coordinates data #not sure if they keep things in the sam order; binding by order is not best practices (joining by unique_id is better

# temp_chelsea_coords <- 
#   st_coordinates(temp_chelsea_sf)
# 
# ## c) Appending the coordinate data  
# pre_chelsea_giveaway_analysis$Longitude <- temp_chelsea_coords[,1]
# pre_chelsea_giveaway_analysis$Latitude  <- temp_chelsea_coords[,2]

```

# 3. Cleaning the Holyoke, MA Giveaway Data 
```{r Reading and Cleaning Giveaway Data Chelsea, echo=TRUE, message=FALSE}
# 1. Comparing the columns to see which ones need to be changed from before
compare_df_cols(chelsea_giveaways, holyoke_giveaways) |>
  as_tibble() |>
  print(n = Inf) # Needed this to help me clear out some of the columns/rows

# 2. Overview of all the variables (including all of the years surveyed)
holyoke_giveaway_overview <-
  holyoke_giveaways |> 
    rename(
      # Unique_ID                  = OID_
      Date_Planted                 = DATEPLANTE
      # New_Address                = nw_ddrs
    , Public_Private               = Pub_Priv
      # Comment_General            = COMMENT
    , Cultivar                     = Cultivar
      # Year_Planted               = GGC_SEA
      # Season_Planted             = GGC_SEA
      # City                       = CITY_GG
    , Family                       = Family
    , Genus                        = Genus
    , Deciduous_Evergreen          = Deciduous
      # Broadleaf_Conifer          = Broadleaf
    , Species                      = Species
    , Native_Status                = Native_Sta
    # , DBH_2021_2023              = DBH_dcr
    , Height_2017                  = Hgt_17 # EM: Still do! Needs cleaning
    # , Owner_Address_P1           = ADDRESS # Needs double checking here
    # , Owner_Address_P2           = OWNERAD # Needs standardization
    , Basal_Sprouts_2017           = BSp_17
      # Comment_Planting           = Cmmnt_1
    , DBH_2017                     = DBH1_17
    , Mortality_Status_2017        = M_17
    , Vigor_2017                   = V_17
    , Land_Use_2017                = LUse_17
    , Site_Type_2017               = StTp_17  
    , Width_2017                   = Wth_17
    , Common_Name                  = commonName
    , Unique_ID_New                = NewTreeID 
    , Site_Type_2024               = StTp_24
    , Land_Use_2024                = LUse_24
    , Basal_Sprouts_2024           = BSp_24 # Seems to be less comprehensive
    , Vigor_2024                   = V_24
    , Conditions_2024              = Con_24 # Condition for all the years
      # Comment_Survey_2024        = Com_24
    , DBH_2024                     = DBH1_24
    , Height_2024                  = Hgt_24
    , Width_2024                   = Wth_24
    , Date_Surveyed                = Date_24
    , Mortality_Status_2024        = M_24
      # Date_Inserted              = CreationDate
      # Author_Inserted            = Creator
      # Date_Edited                = EditDate
      # Author_Edited              = Editor
    , Northing                     = lat  
    , Easting                      = long 
    ) |>
   mutate(City = "HOLYOKE"                      # Need to add for the bind and select in the future
       , Broadleaf_Conifer = NA_character_
       , Comment_General = NA_character_
       , Comment_Survey_2017 = NA_character_
       , Comment_Survey_2024 = NA_character_
       , Address = NA_character_
       , Year_Planted =  NA_character_
       , Season_Planted = NA_character_
   ) 
  
  
# 3a. Figuring out which columns to select for the new one
compare_df_cols(pre_chelsea_giveaway_analysis, holyoke_giveaway_overview) |>
  as_tibble() |>
  print(n = Inf) 

# 3b. Selecting the variables that are in common
pre_holyoke_giveaway_analysis <- 
  holyoke_giveaway_overview |>
  dplyr::select (
      Unique_ID_New                
    , Address                  
    # , Owner_Address_P1             
    # , Owner_Address_P2             
    , City
    , Date_Planted                 
    , Year_Planted                 
    , Season_Planted               
    # , Date_Surveyed                
    # , Date_Inserted                
    # , Author_Inserted              
    # , Date_Edited                  
    # , Author_Edited                
    , Family                       
    , Genus                        
    , Species                      
    , Cultivar                     
    , Common_Name                  
    , Native_Status                
    , Deciduous_Evergreen          
    , Broadleaf_Conifer            
    , Public_Private   
    , Land_Use_2017
    , Land_Use_2024 
    , Site_Type_2017
    , Site_Type_2024  
    , Vigor_2017
    , Vigor_2024              
    , Mortality_Status_2017   
    , Mortality_Status_2024   
    # , Conditions_2017 There does not seem to be a conditions in 2017
    , Conditions_2024
    , DBH_2017 
    , DBH_2024    
    , Height_2017  
    , Height_2024  
    , Width_2017  
    , Width_2024 
    , Basal_Sprouts_2017  
    , Basal_Sprouts_2024      
    , Comment_General
    , Comment_Survey_2017
    , Comment_Survey_2024
    , Easting                      
    , Northing                     
  ) 

# 4. Getting the lat and long of the variables for further analysis
## a) Transforming into an SF object based off of Massachusetts State Plane, NAD83, feet
temp_holyoke_sf <- 
  pre_holyoke_giveaway_analysis |>
  st_as_sf(coords = c("Easting", "Northing"), crs = 26986) |> # TODO , remove = FALSE but then rename Easting and Northing
  st_transform(crs = 4326)  

## b) Receiving the coordinates data
temp_holyoke_coords <- 
  st_coordinates(temp_holyoke_sf)

## c) Appending the coordinate data  
pre_holyoke_giveaway_analysis$Longitude <- temp_holyoke_coords[,1]
pre_holyoke_giveaway_analysis$Latitude  <- temp_holyoke_coords[,2]

# 5. Reverse geocoding for the addresses # TODO why do you need addresses?
# a) Finding all the addresses to append
giveaway_with_addresses <-
  pre_holyoke_giveaway_analysis |>
  reverse_geocode(
    lat = Latitude,
    long = Longitude,
    method = "arcgis",
    full_results = TRUE # TODO if its long and slow, save it out and read in the results. 
  )

# b) Creating new data frame to append
shortlabel_data <-
  giveaway_with_addresses |>
  dplyr::select(Unique_ID_New, ShortLabel)

# c) Appending the data
pre_holyoke_giveaway_analysis <-
  pre_holyoke_giveaway_analysis |>
  left_join(shortlabel_data, by = "Unique_ID_New") |>
  mutate(Address = ShortLabel) |>
  dplyr::select(-ShortLabel)

# Approximately ~110 that need fixing; DL: not sure how urgent since we are not doing analysis with address, but added it so it was nice to have

# 6. Comparing the columns again
compare_df_cols(pre_chelsea_giveaway_analysis, pre_holyoke_giveaway_analysis) |>
  as_tibble() |>
  print(n = Inf) 

```

# 4. Combining the Chelsea, MA and Holyoke, MA Giveaway Data
```{r}
# 1. Combining both of the datasets and making it time long
pre_hero_tree_giveaway <- 
  bind_rows(
    pre_chelsea_giveaway_analysis
  , pre_holyoke_giveaway_analysis
    ) |>
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) |> # TODO why make spatial AGAIN, you already have these data as sf object, right?
  mutate(Row_ID = row_number()) |> # Need this since Unique_ID_New isn't really unique; also meeds to be before the pivot to maintain # TODO, we already found out the uniqe IDs are legit, why make another new ID?
  pivot_longer(
    cols = ends_with("_2017") | ends_with("_2024") # Selects these in specific
  , names_to = c(".value", "Year_Surveyed")
  , names_pattern = "(.*)_(2017|2024)" # Gives them the written pattern as either 2017 or 2023
  )

```

# 5. Creating the appending columns for the final HERO Giveaway Dataset
```{r}
# 1a. Creating summary table of Broadleaf and Conifers for a join
pre_broadleaf_conifer_table_v1 <- 
  pre_hero_tree_giveaway |>
  st_drop_geometry() |>
  filter(!is.na(Broadleaf_Conifer)) |> 
  group_by(Species, Broadleaf_Conifer) |>  
  summarize(Count = n(), .groups = "drop") |> 
  arrange(Species) |>
  dplyr::select(-Count) 

# 1b. Checking if there any duplicates here
pre_broadleaf_conifer_table_v1 |>
  count(Species) |>
  filter(n > 1) # Nope, so they are all unique :)

# 1c. Creating a tibble of the future missing Broadleaf_Conifer categorizations
pre_broadleaf_conifer_table_v2 <- 
  tribble(
  ~Species,                      ~Broadleaf_Conifer
  , "Aesculus hippocastanum"  , "Broadleaf"                     
  , "Aesculus x carnea"       , "Broadleaf"               
  , "Amelanchier canadensis"  , "Broadleaf"                 
  , "Eucommia ulmoides"       , "Broadleaf"             
  , "Halesia monticola"       , "Broadleaf"             
  , "Malus x domestica"       , "Broadleaf"           
  , "Prunus avium"            , "Broadleaf"       
  , "Prunus persica"          , "Broadleaf"           
  , "Prunus salicina"         , "Broadleaf"           
  , "Pyrus communis"          , "Broadleaf"          
  , "Sorbus alnifolia"        , "Broadleaf"             
  , "Styrax japonicus"        , "Broadleaf"               
  , "Thuja plicata"           , "Conifer"         
  , "Ulmus parvifolia"        , "Broadleaf"             
  , "Ulmus spp."              , "Broadleaf"
  )

# 1d. Combining both tables for the join
broadleaf_conifer_table <-
 bind_rows(
    pre_broadleaf_conifer_table_v1,
    pre_broadleaf_conifer_table_v2
    ) 

# 2a. Creating the iTree Final Table
pre_i_tree_table_v1 <- 
  read_excel(
    "input_data/General/Create_iTree_spp_codes_from_inventory_list.xls.xlsx"
    , sheet = "i-Tree Species List"
  ) |>
 mutate( #This is to make it mergeable
    Species = str_c(`Genus Name`, `Species Name`, sep = " "),
    Species = str_to_lower(Species),
    Species = str_replace(Species, "^\\w", toupper(str_sub(Species, 1, 1)))  #Ensures the first letter is capitalized
  ) |>
  rename(Height_Maturity = `Height at Maturity (feet)`
       , i_Tree_Code        = `Species Code`
       , Growth_Form        = `Growth Form`
       , Percent_Leaf_Type  = `Percent Leaf Type`
       , Leaf_Type          = `Leaf Type`
       , Growth_Rate        = `Growth Rate`
       )

# FIXM
# 2b. Checking the unmatched species
matched_species <- #Finding those matched
  pre_hero_tree_giveaway$Species %in% pre_i_tree_table_v1$Species # DHL does not run.

#Finding those unmatched # DHL use %nin% or dplyr::anti_join or tidylog::anti_join for clarity and sanity instead.
  unique(pre_hero_tree_giveaway$Species[!(pre_hero_tree_giveaway$Species %in% pre_i_tree_table_v1$Species)])
  
# 2c. Creating the index table and reading it in
pre_i_tree_table_v2 <- 
  read_excel("input_data/General/i_Tree_Appendix.xls.xlsx"
           , sheet = "i-Tree Species List"
           , n_max = 19) |>
  dplyr::select(1:8)

# DL: There are some odd species without a noticaebale TREEID, being the following: Quercus x warei, Prunus x incam, Malus x domestica. Other [genus spp.] had little to no information—those were also not helpful. EM: I think those were just added as it came from the sheet they gave and tried to find the best one, including other

# 2d. Merging both index tables for future i-Tree analysis
i_tree_table <- 
  bind_rows(
    pre_i_tree_table_v1
  , pre_i_tree_table_v2
    ) |>
  dplyr::select(-`Genus Name`, -`Species Name`, -Synonym, -Family, -Order, -Class, -`Common Name`)

```

# 6. Making the final HERO Giveaway Dataset
```{r}
# 1. Creating the final HERO tree giveaway table
hero_tree_giveaway <- 
  pre_hero_tree_giveaway |>
  mutate(Address = str_to_upper(Address)
       , Public_Private = str_to_title(Public_Private)) |> #Making all the addresses capitals
  arrange(City, Address) |>
  mutate(Date_Planted = mdy(Date_Planted)) |>
  mutate(Date_Planted = if_else(is.na(Date_Planted), as.Date("2021-05-19"), Date_Planted)) |> 
  mutate(
    Year_Planted = year(Date_Planted),
    Month = month(Date_Planted),
    Season_Planted = case_when(
      Month %in% c(3, 4, 5, 6, 7) ~ "SPRING" #DL: Please check your email to double check this # DHL ask John Rogan
    , Month %in% c(8, 9, 10, 11) ~ "FALL" #EM: Please check your email to double check this
    , TRUE ~ NA_character_      
    )
  ) |>
  dplyr::select(-Month, -Broadleaf_Conifer) |>
  mutate(Vigor = as.character(Vigor)
       , Vigor = case_when(
            Vigor == "1" ~ "100% to 90% Full"
          , Vigor == "2" ~ "90% to 75% Full"
          , Vigor == "3" ~ "75% to 50% Full"
          , Vigor == "4" ~ "50% or less"
          , Vigor == "5" ~ "Unsure" #EM: Please check your email to double check this
          , TRUE ~ Vigor)
       , Site_Type = case_when(
            Site_Type == "SC" ~ "Sidewalk Cutout"
          , Site_Type == "BY" ~ "Backyard"
          , Site_Type == "FY" ~ "Front Yard"
          , Site_Type == "OM" ~ "Other Maintained"
          , Site_Type == "SY" ~ "Side Yard"
          , Site_Type == "MP" ~ "Maintained Park"
          , Site_Type == "SP" ~ "Sidewalk Planting Strip"
          , TRUE ~ Site_Type)
       , Mortality_Status = case_when(
            Mortality_Status == "SD" ~ "Standing Dead"
          , Mortality_Status == "A" ~ "Alive"
          , Mortality_Status == "R" ~ "Removed"
          , Mortality_Status == "Y" ~ "Unknown" #EM: Please check, not sure what this means
       ) 
       , Land_Use = case_when(
            Land_Use == "MFR"   ~ "Multi-Family Residential"               
          , Land_Use == "SFR-D" ~ "Single-Family Detached"               
          , Land_Use == "SFR-A" ~ "Single-Family Attached"   
          , Land_Use == "SFR"   ~ "Single-Family General"
          , Land_Use == "INST"  ~ "Institutional"               
          , Land_Use == "COMM"  ~ "Commercial"               
          , Land_Use == "MP"    ~ "Maintained Park"               
          , Land_Use == "V"     ~ "Vacant"      
          , Land_Use == "MX"    ~ "Mixed Use"            
          , Land_Use == "IND"   ~ "Industrial"              
          , Land_Use == "O"     ~ "Other"            
          , Land_Use == "TR"    ~ "Transportation"               
          , Land_Use == "UT"    ~ "Unsure" #EM: Please fix this when push comes to shove
          , TRUE ~ Land_Use)
        , General_Location = case_when(
            Site_Type %in% c("Sidewalk Cutout", "Sidewalk Planting Strip") ~ "Street Trees"
          , Site_Type %in% c("Backyard", "Front Yard", "Side Yard") ~ "Yard Trees"
          , Site_Type %in% c("Other Maintained", "Maintained Park") ~ "Maintained Area"
          , TRUE ~ NA_character_)
              ) |>
    left_join(broadleaf_conifer_table, by = "Species") |>
    left_join(i_tree_table, by = "Species") |>
    dplyr::select(
      , Row_ID      
      , Address                  
      , City
      , Date_Planted                 
      , Year_Planted                 
      , Season_Planted 
      , Year_Surveyed
      , Family                       
      , Genus                        
      , Species                      
      , Cultivar                     
      , Common_Name
      , i_Tree_Code
      , Growth_Form
      , Percent_Leaf_Type
      , Leaf_Type
      , Growth_Rate
      , Longevity
      , Height_Maturity
      , Native_Status                
      , Deciduous_Evergreen          
      , Broadleaf_Conifer            
      , Public_Private   
      , Land_Use
      , General_Location
      , Site_Type         
      , Vigor             
      , Mortality_Status  
      , Conditions         
      , DBH            
      , Height           
      , Width             
      , Basal_Sprouts     
      , Comment_General
      , Comment_Survey
      , Unique_ID_New   
    ) |>
    rename(
      , New_Tree_ID      = Unique_ID_New #Had a change of mind and wanted to continue having the ID name that was there before
    )

hero_tree_giveaway #Yay :). Should be fully cleaned now and organized. 

```

# 7. Appending the census and property values
```{r}
# 1. Reading and cleaning the different layers
## a. Holyoke Census Data
massachusetts_cbgs <-
  st_read("./input_data/cbg_massachusetts_2025-04-28.gpkg")

 holyoke_boundary <-
  st_read("./input_data/Holyoke/Boundaries/holyoke_boundary.gpkg") |>
  st_transform(st_crs(massachusetts_cbgs))

holyoke_cbgs <- 
  massachusetts_cbgs |> 
  filter(str_detect(GEOID, '25013812002') | str_detect(GEOID, '250138119') | str_detect(GEOID, '250138121') |
           str_detect(GEOID, '250138117') | str_detect(GEOID, '250138120') | str_detect(GEOID, '25013811800') |
           str_detect(GEOID, '250138115') | str_detect(GEOID, '250138116') | str_detect(GEOID, '25013811400')
         ) |> 
   st_intersection(holyoke_boundary) #EM: Please change/rename the columns to be all capitalized in the previous script and change the date

## b. Chelsea Census Data
chelsea_boundary <-
  st_read("./input_data/Chelsea/Boundaries/chelsea_boundary.gpkg") |>
  st_transform(st_crs(massachusetts_cbgs))

chelsea_cbgs <-
  massachusetts_cbgs |> 
  filter(str_detect(GEOID, '25025160')) |> 
  st_intersection(chelsea_boundary) #EM: Please change/rename the columns to be all capitalized in the previous script and change the date

## c. Holyoke Parcel Data
holyoke_parcels <-
  st_read("./input_data/Holyoke/Boundaries/holyoke_property_value.gpkg") |>
  dplyr::select( #DL: Please let me know what other columns may be of interest. Selecting the ones based on our conversation and your prior study looking at FY BY in Boston, MA (will delete this once you decided)
    # , OBJECTID 
    # , MAP_PAR_ID   
    # , LOC_ID       
    # , POLY_TYPE    
    # , MAP_NO       
    # , SOURCE       
    # , PLAN_ID      
    # , LAST_EDIT    
    # , BND_CHK      
    # , NO_MATCH     
    # , TOWN_ID      
    # , PROP_ID      
    , BLDG_VAL     
    , LAND_VAL     
    , OTHER_VAL    
    , TOTAL_VAL    
    # , FY
    , LOT_SIZE     
    , LS_DATE      
    , LS_PRICE     
    # , USE_CODE
    # , SITE_ADDR
    # , ADDR_NUM
    # , FULL_STR
    # , LOCATION
    # , CITY
    # , ZIP
    # , OWNER1
    # , OWN_ADDR
    # , OWN_CITY
    # , OWN_STATE
    # , OWN_ZIP
    # , OWN_CO
    # , LS_BOOK
    # , LS_PAGE
    # , REG_ID
    # , ZONING
    , YEAR_BUILT
    , BLD_AREA
    # , UNITS
    , RES_AREA
    , STYLE        
    # , NUM_ROOMS
    # , LOT_UNITS
    # , STORIES
    # , GlobalID
    # , Shape__Area
    # , Shape__Length
    # , geom         
  ) |>
  rename(
    Building_Value     = BLDG_VAL   
  , Land_Value         = LAND_VAL   
  , Other_Value        = OTHER_VAL  
  , Total_Value        = TOTAL_VAL  
  , Lot_Size           = LOT_SIZE  
  , Last_Sale_Price    = LS_PRICE
  , Last_Sale_Date     = LS_DATE  
  , Year_Built         = YEAR_BUILT
  , Building_Area      = BLD_AREA
  , Residential_Area   = RES_AREA
  , Building_Style     = STYLE 
  ) |>
  dplyr::select(Building_Value, Land_Value, Other_Value, Total_Value, Last_Sale_Date, Last_Sale_Price, Lot_Size, Residential_Area, Building_Area, Building_Style)

# https://massgis.maps.arcgis.com/apps/OnePane/basicviewer/index.html?appid=47689963e7bb4007961676ad9fc56ae9 an issue is that the assessment seems to have different for each specific parcel | DL: What should I do?

## d. Chelsea Parcel Data
chelsea_parcels <-
  st_read("./input_data/Chelsea/Boundaries/chelsea_property_value.gpkg") |>
  rename(
    Building_Value     = BLDG_VAL   
  , Land_Value         = LAND_VAL   
  , Other_Value        = OTHER_VAL  
  , Total_Value        = TOTAL_VAL  
  , Lot_Size           = LOT_SIZE  
  , Last_Sale_Price    = LS_PRICE
  , Last_Sale_Date     = LS_DATE  
  , Year_Built         = YEAR_BUILT
  , Building_Area      = BLD_AREA
  , Residential_Area   = RES_AREA
  , Building_Style     = STYLE 
  ) |>
  dplyr::select(Building_Value, Land_Value, Other_Value, Total_Value, Last_Sale_Date, Last_Sale_Price, Lot_Size, Residential_Area, Building_Area, Building_Style)

# 2. Combining the datasets
## a. Making all the geometry valid prior to joining to one layer each
holyoke_parcels <- st_make_valid(holyoke_parcels)
chelsea_parcels <- st_make_valid(chelsea_parcels)
holyoke_cbgs <- st_make_valid(holyoke_cbgs)
chelsea_cbgs <- st_make_valid(chelsea_cbgs)
hero_tree_giveaway <- st_make_valid(hero_tree_giveaway)

## b. Combining layers for no duplicate columns in the appending stage
all_cbgs <- bind_rows(holyoke_cbgs, chelsea_cbgs)
all_parcels <- bind_rows(holyoke_parcels, chelsea_parcels)

# 2. Appending all of the datasets
hero_tree_giveaway_all <-
  hero_tree_giveaway |>
  st_join(all_parcels, left = TRUE) |>
  st_join(all_cbgs, left = TRUE) #EM: Definitely some column cleaning needs to be done in earlier steps in the case of the census but should be good and looks right for analysis

# 3. Writing out the dataset
hero_tree_giveaway_all |>
  st_write(paste0("input_data/General/hero_tree_giveaway_all_", Sys.Date(), ".gpkg"))
```

# 8. Creating the final double checks of the dataset
```{r}
# Moved in the .gpkg to the input General folder

# 2. DL: If you want to do double checks. I suggest downloading mine which has the 
# direct reverse geocoded so you do not have to go through that process; I commented it out momentarily.
check_hero_tree_giveaway <-
  st_read("input_data/General/hero_tree_giveaway_2025-07-15.gpkg")
# DHL: no changes suggested here, but that would have been nice to know up top :-)
# DHL: no changes suggested here, but you seem to have a lot folders called "General". Be careful you may fool yourself

# missingness
check_hero_tree_giveaway  |> 
 map(~sum(is.na(.))) |>
 bind_rows() |>
 t()

# categorical / text
check_hero_tree_giveaway |> 
  st_drop_geometry() |>
  tidylog::select(-Address) |> 
  mutate_if(is.character, as.factor) |>
  select_if(is.factor) |>
  map(~tabyl(.)) |>
  bind_rows(.id = 'var') |> View()

check_hero_tree_giveaway |> mapview(zcol = 'Year_Planted')

check_hero_tree_giveaway |> 
  st_drop_geometry() |> 
  tabyl(Site_Type)

check_hero_tree_giveaway |> 
  st_drop_geometry() |> 
  group_by(Site_Type, City) |> 
  count() |> 
  ggplot(aes(n, Site_Type)) +
  geom_col() +
  facet_wrap(~City) +
  theme_bw(16) +
  NULL

check_hero_tree_giveaway |> 
  st_drop_geometry() |> 
  tabyl(Site_Type, City) |> 
  adorn_percentages() |> 
  pivot_longer(-Site_Type) |> 
  ggplot(aes(value, Site_Type)) +
  geom_col() +
  facet_wrap(~name) +
  theme_bw(16) +
  NULL
 
# eh not really what I was going for.
check_hero_tree_giveaway |> 
  st_drop_geometry() |> 
  filter(Site_Type == 'Front Yard' | Site_Type == 'Backyard') |> 
  tabyl(Year_Planted, City, Site_Type) |> 
  adorn_percentages() |> 
  bind_rows(.id = "Site_Type") |> 
  pivot_longer(-c(Site_Type, Year_Planted)) |> 
  ggplot(aes(value, Site_Type, fill = Year_Planted)) +
  geom_col() +
  facet_wrap(~name) +
  theme_bw(16) +
  NULL

```

Hi Dexter!

Apologize for how late this is and completely understand if you cannot see it prior to today's meeting. This is the agenda for it:

1. Discuss if there is anything else needed for variables and if it was pivoted correctly
2. Discuss if the Census Data was done correctly or needs to be shifted
3. Discuss what to do with property parcel information; the only available was the most recent which had different assessment years (and could only find that and receive the data through an API package in R); how do you find the vintage ones?
4. Any major errors in the datasets

Also, in terms of progress:
1. Time-long instead of time-wide now and recuperated/corrected the 2017 variables that we are looking at
2. Double-checked the census data and some future inquiries on if the statistics behind it was done correctly
3. Pulled the GIS data of Mass for Property Parcel data using an API package in R
4. Combined both datasets and selected the columns best needed 
5. Created the final subset [still need to filter for FY BY + add mortality booleans for the future] but should be in the beginning process for analysis.

```{r}


(
  df_long <-
  df |> 
  select(dhl_id, neigh : season2, planting_date,  year_planting, starts_with('status_')) |> 
  # filter(status_1 == 1) #|> # ~4% did not live to first year inspection?
  # pivot_longer(starts_with('status_'), values_to = 'status') |> 
  # STOP contributing time (make tibble jagged for pivoting shorter)
  mutate(
    # if you are dead, stay dead (so we can remove you later)
      status_2 = ifelse(status_1 == 1 & status_2 == 0, NA, status_2) # dead at inspection 1, make rest NA part 1 / 2
    , status_5 = ifelse(status_1 == 1 & status_2 == 0, NA, status_2) # dead at inspection 1, make rest NA part 2 / 2
    , status_5 = ifelse(status_1 == 0 & status_2 == 1, NA, status_5) # dead at inspection 2, make rest NA
    ) |> 
  pivot_longer(starts_with('status_'), values_to = 'status', values_drop_na = TRUE) |> 
  mutate(inspection_date =
           lubridate::ymd(as.character(year_planting + as.numeric(str_remove_all(name, 'status_'))), truncated = 2L) # gets year inspected
         + months(6) # + days(14) # gets us to Jul 1 of that year (may want June 1, Jun 15, July 15 for sensitiity)
         , days_ = as.integer(inspection_date - planting_date)
         ) |> 
  # mutate(year_inspection = year_planting + as.numeric(str_remove_all(name, 'status_'))) |> # uses calendar years (2007, 2008, etc.)
  mutate(inspection = as.numeric(str_remove_all(name, 'status_'))) |>                 # uses planting years (1, 2, or 5)
  filter(inspection_date < '2025-07-01') |> # drop inspections that haven't happened yet
  select(dhl_id    # id
         , days_   # time
         # , time = year_inspection
         , status  # event
         , inspection
         , neigh   # covariates
         , pct_owner_occ_2017
         , pct_impervious_2017
         , pct_white_2017
         , poverty_rate_2017
         , season
         , season2
         , year_planting
         , inspection_date
         ) |> 
  # filter(time < 2026) |>
  # Typically you will see 1=event, 0=censored.
  mutate(status = recode(status, `1` = 0, `0` = 1)) |>  # CRITICAL!!!
  distinct() # no issues with duplicates
  )

```

