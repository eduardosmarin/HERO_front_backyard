---
title: "EVST 4960 Data Wrangling"
subtitle: "Creating the Final Product for the Data Analysis"
author: "Eduardo Marin"
date: "`r format(Sys.time())`"
output:
  pFinal_Giveaway_Y2017_Y2024_document:
    toc: true
  html_document:
    theme: flatly
    code_folding: hide
    fig_width: 8
    fig_height: 7
    fig_caption: true
    toc: true
    toc_float: true
    self_contained: true
editor_options:
  chunk_output_type: console
  markdown:
    wrap: 72
---

# 0. Loading the packages
```{r 1. Loading Packages, message=FALSE, include=FALSE}
# 1. Loading all packages

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,   # <--- this suppresses warnings
  message = FALSE    # <--- this suppresses messages
)

packs <-c(
            'janitor'    # cleans things up, also pipe-friendly cross-tabulations
           , 'sf'         # for spatial data support
          , 'tidyverse'  # cuz
          , 'tidylog'    # prints out what was done in dplyr and tidyr
          , 'magrittr'   # for the pipe
          , 'mapview'    # web maps for zooming and panning around
          #, 'beepr'      # makes noise when things are done!
          , 'tictoc'     # timing things.
          , 'raster'
          # , 'doParallel' # does what is says! PARALLEL
          # 'broom.mixed',# tidiers for mixed models AND nlme::gls()
          # , 'lubridate'   # DATES!
          , 'tidycensus' # tidy census package
          , 'tidygeocoder' # geo coding
          , 'leaflet' #creating the interactive mapping elements (more specific)
          , 'shiny'
          , 'leafsync'  # linked maps
          , 'openxlsx'
          , 'readxl'
          )     

#2. If the packages in 'packs' are not already installed, install them
if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
install.packages(setdiff(packs, rownames(installed.packages())))
}
vapply(packs, library, character.only = TRUE, logical(1), logical.return = TRUE, quietly = TRUE)

# 3. Items for tidy census
census_api_key('58fc555c77c229747ade7d9fe50e7c71297cf91a', install = TRUE, overwrite = TRUE)
readRenviron("~/.Renviron")
options(tigris_use_cache = TRUE)
```

Outline of objectives
 1. Home values
 2. Census
 3. General Tree Giveaways
 4. iTree
 5. Final combinination
 6. Testings
 7. Archives

# 1. Property Data: Downloading, cleaning, and subsetting property data for Holyoke, MA and Chelsea, MA (2019 and 2023)
```{r Property Data for Holyoke, MA and Chelsea, MA, echo=FALSE, message=FALSE}
# --- Running Notes --- #
# The data was downloaded from ArcGIS using the Table to Excel tool since it was difficult to read the      additional attribute table using SF in R
# For the inflation data, U.S. Bureau Labor of Statistics was used, particularly from the years 2019 and    2023 to be able to get the value needed for comparisons:           https://www.bls.gov/regions/northeast/data/consumerpriceindex_boston_table.htm
# The identifier for these parcels is the Location_ID. Since the data is being saved out for each individual year, the assumption was that there should be no worries about unification or subdivision of lots, especially since the join will be year and city separate
# --------------------- #

# 1. Cleaning | Creating the standardized names to apply for the dataset
Standard_Names <- c(
  "Unique_ID","Property_ID","Location_ID","Building_Value","Land_Value","Other_Value","Total_Value",
  "Year","Lot_Size","Lot_Date","Lot_Price","Use_Code","Site_Address","Address_Number",
  "Full_Street","Location","City","Zip","OWNER1","OWN_ADDR","OWN_CITY",
  "OWN_STATE","OWN_ZIP","OWN_CO","LS_BOOK","LS_PAGE","REG_ID","Zoning",
  "Year_Built","Building_Area","Units","Residential_Area","Style","Stories","Number_Rooms",
  "Lot_Units","CAMA_ID","Town_ID"
)

# 2. Spatial & Categorical Data | Downloading the categorical and spatial data
## a. Creating the Chelsea (2019) Shapefile #LEAVE AS IS
Chelsea_Property_Data_Append_Y2019 <-
    read_excel("../HERO_front_backyard_data_to_big/Parcel_Data_Sites_Years/Parcel_Data_Assessments_All_Table_to_Excel.xlsx"
            , sheet = "Chelsea_2019"
            , col_types = "text") |> #I need to make the col_type as text because I was having some issues from extracting the data into usable data | Rename to 2019 the value and get rid of the inflation adjusting
    setNames(Standard_Names) |>
    tidylog::select(1:18, 28:36,38) |>
    mutate(across(c(Building_Value, Land_Value, Other_Value, Total_Value,
                  Lot_Size, Lot_Price, Year_Built, Building_Area,
                  Residential_Area, Units, Number_Rooms, Stories),
                as.double)) |>
    mutate(across(Lot_Date, ymd)) |>
    mutate( 
      Building_Value = Building_Value
    , Land_Value = Land_Value
    , Other_Value = Other_Value
    , Total_Value = Total_Value
    , Lot_Price = Lot_Price
    ) |>
  mutate(Year_Dataset = "2019") |>
  rename_with(~ paste0("Parcel_", .x)) |>
  mutate(Time_Period = "Time 1") |>
  tidylog::select(Parcel_Unique_ID, Parcel_Property_ID, Parcel_Location_ID, Parcel_Lot_Size, Parcel_Lot_Date, Parcel_Lot_Units, Parcel_Lot_Price, Parcel_Building_Value, Parcel_Land_Value, Parcel_Other_Value, Parcel_Total_Value, Parcel_Year, Parcel_Style, Parcel_Use_Code, Parcel_Zoning, Parcel_Year_Built, Parcel_Building_Area, Parcel_Residential_Area, Parcel_Units, Parcel_Number_Rooms, Parcel_Stories, Time_Period, Parcel_Year_Dataset)
      
Chelsea_Property_Data_Y2019 <-
  st_read("../HERO_front_backyard_data_to_big/Parcel_Data_Sites_Years/Parcel_Data_Chelsea_CY19_FY19/M057TaxPar_CY19_FY19.shp") |>
  rename(Parcel_Location_ID = LOC_ID) |>
  tidylog::select(4, 13) |>
  left_join(Chelsea_Property_Data_Append_Y2019, by = "Parcel_Location_ID")  |>
  st_transform(crs = 26986)

## b. Creating the Chelsea (2023) Shapefile

Chelsea_Property_Data_Append_Y2023 <-
    read_excel("../HERO_front_backyard_data_to_big/Parcel_Data_Sites_Years/Parcel_Data_Assessments_All_Table_to_Excel.xlsx"
            , sheet = "Chelsea_2023"
            , col_types = "text") |> #I need to make the col_type as text because I was having some issues from extracting the data into usable data 
    setNames(Standard_Names) |>
    tidylog::select(1:18, 28:36,38) |>
    mutate(across(c(Building_Value, Land_Value, Other_Value, Total_Value,
                  Lot_Size, Lot_Price, Year_Built, Building_Area,
                  Residential_Area, Units, Number_Rooms, Stories),
                as.double)) |>
    mutate( 
      Building_Value = Building_Value*(281.082/326.016)
    , Land_Value = Land_Value*(281.082/326.016)
    , Other_Value = Other_Value*(281.082/326.016)
    , Total_Value = Total_Value*(281.082/326.016)
    , Lot_Price = Lot_Price*(281.082/326.016)
    ) |>
# The value that I will do is *(326.016/281.082) #Update to this
    mutate(across(Lot_Date, ymd)) |>
    mutate(Year_Dataset = "2023") |>
   rename_with(~ paste0("Parcel_", .x)) |>
    mutate(Time_Period = "Time 2") |>
  tidylog::select(Parcel_Unique_ID, Parcel_Property_ID, Parcel_Location_ID, Parcel_Lot_Size, Parcel_Lot_Date, Parcel_Lot_Units, Parcel_Lot_Price, Parcel_Building_Value, Parcel_Land_Value, Parcel_Other_Value, Parcel_Total_Value, Parcel_Year, Parcel_Style, Parcel_Use_Code, Parcel_Zoning, Parcel_Year_Built, Parcel_Building_Area, Parcel_Residential_Area, Parcel_Units, Parcel_Number_Rooms, Parcel_Stories, Time_Period, Parcel_Year_Dataset)

Chelsea_Property_Data_Y2023 <-
  st_read("../HERO_front_backyard_data_to_big/Parcel_Data_Sites_Years/Parcel_Data_Chelsea_CY23_FY24/M057TaxPar_CY23_FY24.shp") |>
  rename(Parcel_Location_ID = LOC_ID) |>
  tidylog::select(4, 13) |>
  left_join(Chelsea_Property_Data_Append_Y2023, by = "Parcel_Location_ID") |>
  st_transform(crs = 26986)
  
  
## c. Creating the Holyoke (2019) Shapefile
Holyoke_Property_Data_Append_Y2019 <-
    read_excel("../HERO_front_backyard_data_to_big/Parcel_Data_Sites_Years/Parcel_Data_Assessments_All_Table_to_Excel.xlsx"
            , sheet = "Holyoke_2019"
            , col_types = "text") |> #I need to make the col_type as text because I was having some issues from extracting the data into usable data 
    setNames(Standard_Names) |>
    tidylog::select(1:18, 28:36,38) |>
    mutate(across(c(Building_Value, Land_Value, Other_Value, Total_Value,
                  Lot_Size, Lot_Price, Year_Built, Building_Area,
                  Residential_Area, Units, Number_Rooms, Stories),
                as.double)) |>
   mutate( 
      Building_Value = Building_Value
    , Land_Value = Land_Value
    , Other_Value = Other_Value
    , Total_Value = Total_Value
    , Lot_Price = Lot_Price
    ) |>
    mutate(across(Lot_Date, ymd)) |>
    mutate(Year_Dataset = "2019") |>
    mutate( 
      Building_Value = Building_Value # <- The value from inflation
    , Land_Value = Land_Value #move the new stuff 
    , Other_Value = Other_Value
    , Total_Value = Total_Value
    , Lot_Price = Lot_Price
    ) |>
  rename_with(~ paste0("Parcel_", .x)) |>
  mutate(Time_Period = "Time 1") |>
  tidylog::select(Parcel_Unique_ID, Parcel_Property_ID, Parcel_Location_ID, Parcel_Lot_Size, Parcel_Lot_Date, Parcel_Lot_Units, Parcel_Lot_Price, Parcel_Building_Value, Parcel_Land_Value, Parcel_Other_Value, Parcel_Total_Value, Parcel_Year, Parcel_Style, Parcel_Use_Code, Parcel_Zoning, Parcel_Year_Built, Parcel_Building_Area, Parcel_Residential_Area, Parcel_Units, Parcel_Number_Rooms, Parcel_Stories, Time_Period, Parcel_Year_Dataset)
      
Holyoke_Property_Data_Y2019 <-
  st_read("../HERO_front_backyard_data_to_big/Parcel_Data_Sites_Years/Parcel_Data_Holyoke_CY19_FY20/M137TaxPar_CY19_FY20.shp") |>
  rename(Parcel_Location_ID = LOC_ID) |>
  tidylog::select(4, 13) |>
  left_join(Holyoke_Property_Data_Append_Y2019, by = "Parcel_Location_ID")  |>
  st_transform(crs = 26986)

## d. Creating the Holyoke (2023) Shapefile
Holyoke_Property_Data_Append_Y2023 <-
    read_excel("../HERO_front_backyard_data_to_big/Parcel_Data_Sites_Years/Parcel_Data_Assessments_All_Table_to_Excel.xlsx"
            , sheet = "Holyoke_2023"
            , col_types = "text") |> #I need to make the col_type as text because I was having some issues from extracting the data into usable data 
   setNames(Standard_Names) |>
    tidylog::select(1:18, 28:36,38) |>
    mutate(across(c(Building_Value, Land_Value, Other_Value, Total_Value,
                  Lot_Size, Lot_Price, Year_Built, Building_Area,
                  Residential_Area, Units, Number_Rooms, Stories),
                as.double)) |>
     mutate( 
      Building_Value = Building_Value*(281.082/326.016)
    , Land_Value = Land_Value*(281.082/326.016)
    , Other_Value = Other_Value*(281.082/326.016)
    , Total_Value = Total_Value*(281.082/326.016)
    , Lot_Price = Lot_Price*(281.082/326.016)
    ) |>
    mutate(across(Lot_Date, ymd)) |>
    mutate(Year_Dataset = "2023") |>
    rename_with(~ paste0("Parcel_", .x)) |>
    mutate(Time_Period = "Time 2") |>
  tidylog::select(Parcel_Unique_ID, Parcel_Property_ID, Parcel_Location_ID, Parcel_Lot_Size, Parcel_Lot_Date, Parcel_Lot_Units, Parcel_Lot_Price, Parcel_Building_Value, Parcel_Land_Value, Parcel_Other_Value, Parcel_Total_Value, Parcel_Year, Parcel_Style, Parcel_Use_Code, Parcel_Zoning, Parcel_Year_Built, Parcel_Building_Area, Parcel_Residential_Area, Parcel_Units, Parcel_Number_Rooms, Parcel_Stories, Time_Period, Parcel_Year_Dataset)

Holyoke_Property_Data_Y2023 <-
  st_read("../HERO_front_backyard_data_to_big/Parcel_Data_Sites_Years/Parcel_Data_Holyoke_CY23_FY23/M137TaxPar_CY23_FY23.shp") |>
  rename(Parcel_Location_ID = LOC_ID) |>
  tidylog::select(4, 13) |>
  left_join(Holyoke_Property_Data_Append_Y2023, by = "Parcel_Location_ID") |>
  st_transform(crs = 26986)

```

# 2. Census Data: Downloading and cleaning for Holyoke, MA and Chelsea, MA (2017 and 2023)
```{r Census Data for Holyoke, MA and Chelsea, MA, echo=FALSE, message=FALSE}
# 0. Archived: Census and Address Code for Geopackages # Refer to this

# 1. Reading CBGs in 2022 for General Analysis
Massachusetts_CBG_Data_Y2022 <-
  st_read("input_data/General/Massachusetts_CBG_Data_Y2022.gpkg")

# 2. Reading Holyoke, MA and Chelsea, MA boundaries 
## a. Reading the Holyoke boundary
Holyoke_Boundary <-
  st_read("input_data/Holyoke/Boundaries/holyoke_boundary.gpkg") |>
  st_transform(st_crs(Massachusetts_CBG_Data_Y2022)) # They both have the same projections so it doesn't matter

## b. Reading the Chelsea boundary
Chelsea_Boundary <-
  st_read("input_data/Chelsea/Boundaries/chelsea_boundary.gpkg") |>
  st_transform(st_crs(Massachusetts_CBG_Data_Y2022)) # Likewise, they both have the same projections so it shouldn't matter

#-# ESM to DHL: Technically, no need to this separaetly for each year for the CBGs. However, to not break the code, decided to keep as is for simplicity sake. 

# 3. Sub selecting the Holyoke, MA and Chelsea, MA specific block 
## b. Figuring this out for Chelsea Y2017
Chelsea_CBG_Data_Y2017 <-
  Massachusetts_CBG_Data_Y2022[
  st_intersects(Massachusetts_CBG_Data_Y2022, Chelsea_Boundary, sparse = FALSE)[, 1], ] |>
  filter(!Census_GEOID %in% c("250173424023", "250173424024", "250173426002", "250173421014",
      "250173421013", "250251701023", "250251701013", "250251706012"
      , "250173424004", "250251701003", "250251701006" #These three need to be added for 2017 for some reasons
      )) |>
  st_transform(st_crs(Massachusetts_CBG_Data_Y2022)) 

## b. Figuring this out for Chelsea Y2023
Chelsea_CBG_Data_Y2023 <-
  Massachusetts_CBG_Data_Y2022[
  st_intersects(Massachusetts_CBG_Data_Y2022, Chelsea_Boundary, sparse = FALSE)[, 1], ] |>
  filter(!Census_GEOID %in% c("250173424023", "250173424024", "250173426002", "250173421014",
      "250173421013", "250251701023", "250251701013", "250251706012")) |> # Could also use %nin%
  st_transform(st_crs(Massachusetts_CBG_Data_Y2022)) 
  
#-# Double checked both of these: they seem good above!
## c. Figuring this out for Holyoke Y2017
Holyoke_CBG_Data_Y2017 <-
  Massachusetts_CBG_Data_Y2022[
  st_intersects(Massachusetts_CBG_Data_Y2022, Holyoke_Boundary, sparse = FALSE)[, 1],
] |>
  filter(!Census_GEOID %in% c(
    "250138122021", "250138111023", "250138111022", "250138111021",
    "250138111012", "250138111024", "250138111011", "250138113013",
    "250158211012", "250158211014", "250158213001", "250158225004",
    "250158211012", "250158213003", "250158223001", "250158225004",
    "250138125004", "250158224012", "250158214004"
    , "250138122022" #This one needed to be added for 2017 for some reasons
  )) |>
  st_transform(st_crs(Massachusetts_CBG_Data_Y2022))

## c. Figuring this out for Holyoke Y2023
Holyoke_CBG_Data_Y2023 <-
  Massachusetts_CBG_Data_Y2022[
  st_intersects(Massachusetts_CBG_Data_Y2022, Holyoke_Boundary, sparse = FALSE)[, 1],
] |>
  filter(!Census_GEOID %in% c(
    "250138122021", "250138111023", "250138111022", "250138111021",
    "250138111012", "250138111024", "250138111011", "250138113013",
    "250158211012", "250158211014", "250158213001", "250158225004",
    "250158211012", "250158213003", "250158223001", "250158225004",
    "250138125004", "250158224012", "250158214004"
  )) |>
  st_transform(st_crs(Massachusetts_CBG_Data_Y2022)) 
```

# 3. Preliminary Giveaway Data: Cleaning and making it ready for the survivorship study for Holyoke, MA and Chelsea, MA (2017 and 2024)
```{r Preliminary Data for Holyoke, MA and Chelsea, MA, echo=FALSE, message=FALSE}
# 1. Reading in all the simple spreadsheets 
## a) Reading in the Chelsea, MA Giveaway Spreadsheet
Pre_Chelsea_Giveaways <-
  read_csv("input_data/Chelsea/Tree Giveaways/2017CorrectedChelseaAllTreesComplete.csv")

## b) Reading in the Holyoke, MA Giveaway Spreadsheet
Pre_Holyoke_Giveaways <-
  read_csv("input_data/Holyoke/Tree Giveaways/holy_random_clean_fixed.csv") 

# 2. Cleaning early the datasets Chelsea, MA and Holyoke, MA before Giveaway data
## a) Renaming and simple cleaning the Chelsea, MA Dataset
Pre_Chelsea_Giveaway_Data_Y2017_Y2024 <-
  Pre_Chelsea_Giveaways |>
    rename(
      Date_Planted                 = DATEPLANTE
    , Address                      = nw_ddrs
    , Public_Private               = GGC_PUB
    , Comment_General              = COMMENT
    , Cultivar                     = Cultivar
    , Year_Planted                 = GGC_YEA
    # , Season_Planted               = GGC_SEA
    , City                         = CITY_GG
    , Family                       = Family
    , Genus                        = Genus
    , Deciduous_Evergreen          = Deciduous 
    , Broadleaf_Conifer            = Broadleaf
    , Species                      = Species
    , Native_Status                = Native_Sta
    , Height_2017                  = Hght_17 # EM: Still needs cleaning if you want to use
    , Owner_Address_P1             = ADDRESS # Needs double checking here
    , Owner_Address_P2             = OWNERAD # Needs standardization
    , Basal_Sprouts_2017           = BSp_17
    , Comment_Survey_2017          = Cmmnt_1
    , DBH_2017                     = DBH1_17
    , Mortality_Status_2017        = M_17
    , Vigor_2017                   = V_17
    # , Land_Use_2017                = LUse_17
    # , Site_Type_2017               = StTp_17  
    , Width_2017                   = Wth_17
    , Common_Name                  = CommonName
    , Unique_ID                    = OID_ #EM: Was a mistake previously 
    , Site_Type                    = StTp_24
    , Land_Use                     = LUse_24
    , Basal_Sprouts_2024           = Bsp_24 # Seems to be less comprehensive
    , Vigor_2024                   = V_24
    , Conditions_2024              = Con_24 # Condition for all the years
    , Comment_Survey_2024          = Com_24
    , DBH_2024                     = DBH1_24
    , Height_2024                  = Hgt_24
    , Width_2024                   = Wth_24
    , Mortality_Status_2024        = M_24
    , Date_Surveyed_2024           = D_24
    # , Date_Inserted                = CreationDate
    # , Author_Inserted              = Creator
    # , Date_Edited                  = EditDate
    # , Author_Edited                = Editor
    , Easting                      = X
    , Northing                     = Y
  ) |>
  mutate(Date_Surveyed_2017 = NA_character_) |>
  tidylog::select (
      Unique_ID              
    , Address                  
    # , Owner_Address_P1             
    # , Owner_Address_P2             
    , City                         
    , Date_Planted
    , Date_Surveyed_2017
    , Date_Surveyed_2024
    # , Year_Planted
    # , Season_Planted               
    , Family                       
    , Genus                        
    , Species                      
    , Cultivar                     
    , Common_Name                  
    , Native_Status                
    , Deciduous_Evergreen          
    , Broadleaf_Conifer            
    , Public_Private    
    # , Land_Use_2017
    , Land_Use
    # , Site_Type_2017  
    , Site_Type     
    , Vigor_2017
    , Vigor_2024     
    , Mortality_Status_2017
    , Mortality_Status_2024
    # , Conditions_2017 This does not seem to exist
    , Conditions_2024         
    , DBH_2017
    , DBH_2024     
    , Height_2017
    , Height_2024    
    , Width_2017
    , Width_2024 
    , Basal_Sprouts_2017
    , Basal_Sprouts_2024   
    , Comment_General              
    , Comment_Survey_2017             
    , Comment_Survey_2024          
    , Easting                      
    , Northing                     
  ) |>
  mutate(
     Date_Planted       = mdy(Date_Planted)  #Need this for "Time_in_Ground"
   , Date_Surveyed_2017 = mdy(Date_Surveyed_2017)
  ) |>
  mutate(
    Date_Surveyed_2024 = str_trim(Date_Surveyed_2024) # Removes extra spaces / might not need this
  , Date_Surveyed_2024 = str_replace(Date_Surveyed_2024, " .*$", ""), # Finds the first space and deletes everything afterwards
  , Date_Surveyed_2024 = mdy(Date_Surveyed_2024) # Puts it in MYD
  )

## a) Renaming and simple cleaning the Holyoke, MA Dataset
# 2. Overview of all the variables (including all of the years surveyed)
Pre_Holyoke_Giveaway_Data_Y2017_Y2024 <-
  Pre_Holyoke_Giveaways |> 
    rename(
      # Unique_ID                  = OID_
      Date_Planted                 = DATEPLANTE
      # New_Address                = nw_ddrs
    , Public_Private               = Pub_Priv
      # Comment_General            = COMMENT
    , Cultivar                     = Cultivar
    # , Year_Planted               = GGC_SEA
      # City                       = CITY_GG
    , Family                       = Family
    , Genus                        = Genus
    , Deciduous_Evergreen          = Deciduous
      # Broadleaf_Conifer          = Broadleaf
    , Species                      = Species
    , Site_Type                    = StTp_24 #EM: PLEASE NOTE FOR DEXTER THIS IS STRANGE!
    , Native_Status                = Native_Sta
    # , DBH_2021_2023              = DBH_dcr
    , Height_2017                  = Hgt_17 # EM: Needs cleaning if time affords
    # , Owner_Address_P1           = ADDRESS 
    # , Owner_Address_P2           = OWNERAD 
    , Basal_Sprouts_2017           = BSp_17
      # Comment_Planting           = Cmmnt_1
    , DBH_2017                     = DBH1_17
    , Mortality_Status_2017        = M_17
    , Vigor_2017                   = V_17
    # , Land_Use_2017                = LUse_17
    # , Site_Type_2017               = StTp_17  
    , Width_2017                   = Wth_17
    , Common_Name                  = commonName
    , Unique_ID                    = NewTreeID 
    , Land_Use                     = LUse_24
    , Basal_Sprouts_2024           = BSp_24 # Seems to be less comprehensive
    , Vigor_2024                   = V_24
    , Conditions_2024              = Con_24 # Condition for all the years
      # Comment_Survey_2024        = Com_24
    , DBH_2024                     = DBH1_24
    , Height_2024                  = Hgt_24
    , Width_2024                   = Wth_24
    , Mortality_Status_2024        = M_24
    , Date_Surveyed_2017           = Observe_17
    , Date_Surveyed_2024           = Date_24
    , Northing                     = lat  
    , Easting                      = long 
    ) |>
   mutate(City = "HOLYOKE"                      # Need to add for the bind and select in the future
       , Broadleaf_Conifer = NA_character_
       , Comment_General = NA_character_
       , Comment_Survey_2017 = NA_character_
       , Comment_Survey_2024 = NA_character_
       , Address = NA_character_
   ) |>
  tidylog::select (
      Unique_ID                
    , Address                  
    # , Owner_Address_P1             
    # , Owner_Address_P2             
    , City
    , Date_Planted    
    # , Year_Planted
    , Date_Surveyed_2017
    , Date_Surveyed_2024
    , Family                       
    , Genus                        
    , Species                      
    , Cultivar                     
    , Common_Name                  
    , Native_Status                
    , Deciduous_Evergreen          
    , Broadleaf_Conifer            
    , Public_Private   
    # , Land_Use_2017
    , Land_Use 
    # , Site_Type_2017
    , Site_Type  
    , Vigor_2017
    , Vigor_2024              
    , Mortality_Status_2017   
    , Mortality_Status_2024   
    # , Conditions_2017 There does not seem to be a conditions in 2017
    , Conditions_2024
    , DBH_2017 
    , DBH_2024    
    , Height_2017  
    , Height_2024  
    , Width_2017  
    , Width_2024 
    , Basal_Sprouts_2017  
    , Basal_Sprouts_2024      
    , Comment_General
    , Comment_Survey_2017
    , Comment_Survey_2024
    , Easting                      
    , Northing                     
  ) |>
  mutate(
     Date_Planted       = mdy(Date_Planted)  #Need this for "Time_in_Ground"
   , Date_Surveyed_2017 = mdy(Date_Surveyed_2017)
   , Date_Surveyed_2024 = mdy(Date_Surveyed_2024)
  )

# 3. Getting the lat and long for Chelsea, MA & Holyoke, MA
## a) Figuring out the Lat and Long Coordinates for Chelsea, MA
### i) Making it into Massachusetts State Plane, NAD83, feet
Pre_Chelsea_Giveaway_Coords <- 
  Pre_Chelsea_Giveaway_Data_Y2017_Y2024 |>
  st_as_sf(coords = c("Easting", "Northing"), crs = 26986) |>
  st_transform(crs = 4326)  

### ii) Receiving the coordinates data
Chelsea_Giveaway_Coords <- 
  st_coordinates(Pre_Chelsea_Giveaway_Coords)

### iii) Appending the coordinates data 
Pre_Chelsea_Giveaway_Data_Y2017_Y2024$Longitude <- Chelsea_Giveaway_Coords[,1]
Pre_Chelsea_Giveaway_Data_Y2017_Y2024$Latitude  <- Chelsea_Giveaway_Coords[,2]

## a) Figuring out the Lat and Long Coordinates and Addresses for Holyoke, MA
### i) Making it into Massachusetts State Plane, NAD83, feet
Pre_Holyoke_Giveaway_Coords <- 
  Pre_Holyoke_Giveaway_Data_Y2017_Y2024 |>
  st_as_sf(coords = c("Easting", "Northing"), crs = 26986) |>
  st_transform(crs = 4326)  

### ii) Receiving the coordinates data
Holyoke_Giveaway_Coords <- 
  st_coordinates(Pre_Holyoke_Giveaway_Coords)

### iii) Appending the coordinates data 
Pre_Holyoke_Giveaway_Data_Y2017_Y2024$Longitude <- Holyoke_Giveaway_Coords[,1]
Pre_Holyoke_Giveaway_Data_Y2017_Y2024$Latitude  <- Holyoke_Giveaway_Coords[,2]

#-# Holyoke, MA needs Address #-#
# 0. Archived: Census and Address Code for Geopackages # Refer to this

## iv) Reading the address data
Holyoke_Giveaway_Addresses <-
  st_read("input_data/Holyoke/Holyoke_Giveaway_Addresses.gpkg"
  )

### v) Creating new data frame to append
Holyoke_Short_Label <-
  Holyoke_Giveaway_Addresses |>
  tidylog::select(Unique_ID, ShortLabel)

### vi) Appending the data
Pre_Holyoke_Giveaway_Data_Y2017_Y2024 <-
  Pre_Holyoke_Giveaway_Data_Y2017_Y2024 |>
  left_join(Holyoke_Short_Label, by = "Unique_ID") |>
  mutate(Address = ShortLabel) |>
  tidylog::select(-ShortLabel)

# 4. Finding the Days since Planted for Chelsea, MA and Holyoke, MA | Chelsea, 2017 is missing 
## a) Finding the Days since Planted for Holyoke, MA
Holyoke_Giveaway_Data_Y2017_Y2024 <- 
  Pre_Holyoke_Giveaway_Data_Y2017_Y2024 |>
  mutate(
    Days_Since_Planted_2017 = as.numeric(Date_Surveyed_2017 - Date_Planted)
  , Days_Since_Planted_2024 = as.numeric(Date_Surveyed_2024 - Date_Planted)
  )

## b) Finding the Days since Planted for Chelsea, MA
### i) Double checking if the month where the survey occur are usually one season to be able to extrapolate easier
Holyoke_Surveyed_Month_Y2017 <-
  Holyoke_Giveaway_Data_Y2017_Y2024 |>
  filter(!is.na(Date_Surveyed_2017), !is.na(Days_Since_Planted_2017)) |> 
  mutate(
    Month_Number   = month(Date_Surveyed_2017)
  , Month_Label = month(Date_Surveyed_2017, label = TRUE, abbr = TRUE)
  ) |>
  group_by(Month_Label, Month_Number) |>
  summarise(
    n = n()
  , Median_Days_Since_Planted_2017 = median(Days_Since_Planted_2017, na.rm = TRUE), #Seeing which to use: median vs mean
  , Mean_Days_Since_Planted_2017   = mean(Days_Since_Planted_2017, na.rm = TRUE),
  , .groups = "drop"
  ) |>
  arrange(Month_Number) |>
  tidylog::select(-Month_Number)
  
as.data.frame(Holyoke_Surveyed_Month_Y2017) 

print(Holyoke_Surveyed_Month_Y2017) # Majority in June

### ii) Calculating all of the median survey dates to be able to do the aggregation for Chelsea, MA
Holyoke_Median_Survey_Y2017 <- # This is to get the base value
  median(Holyoke_Giveaway_Data_Y2017_Y2024$Date_Surveyed_2017, na.rm = TRUE)

Holyoke_Median_Survey_Y2024 <- # This is for the first part of the offset
  median(Holyoke_Giveaway_Data_Y2017_Y2024$Date_Surveyed_2024, na.rm = TRUE)

Chelsea_Median_Survey_Y2024 <- # This is for the second part of the offset
  median(Pre_Chelsea_Giveaway_Data_Y2017_Y2024$Date_Surveyed_2024, na.rm = TRUE)

### iii) Creating the offset to apply for Chelsea, MA and creating date
Offset_Y2024 <- 
  as.integer(Chelsea_Median_Survey_Y2024 - Holyoke_Median_Survey_Y2024) 

Chelsea_Median_Survey_Y2017 <- Holyoke_Median_Survey_Y2017 + days(Offset_Y2024)

### iv) Applying all of this data 
Chelsea_Giveaway_Data_Y2017_Y2024 <-
  Pre_Chelsea_Giveaway_Data_Y2017_Y2024 |>
  mutate(
    Has_Survey_2017 = !is.na(Mortality_Status_2017) & Mortality_Status_2017 != "" #Checking that has a mortality present + and making sure it is not an empty string
  , Date_Surveyed_2017 = case_when(
      is.na(Date_Surveyed_2017) & Has_Survey_2017 & !is.na(Date_Planted) ~ if_else(Date_Planted > Chelsea_Median_Survey_Y2017, Date_Planted, Chelsea_Median_Survey_Y2017), #More of a safety check to see if it flags any weird trees that were before the average survey date | None that it flagged
      TRUE ~ Date_Surveyed_2017
    )
  ) |>
  tidylog::select(-Has_Survey_2017) |>
  mutate(
    Days_Since_Planted_2017 = as.numeric(Date_Surveyed_2017 - Date_Planted)
  , Days_Since_Planted_2024 = as.numeric(Date_Surveyed_2024 - Date_Planted)
  )
  
# 5. Combining both data sheets before and afterwards
## a) Double checking to make sure they have the same items for curves
compare_df_cols(Holyoke_Giveaway_Data_Y2017_Y2024, Chelsea_Giveaway_Data_Y2017_Y2024) |>
  as_tibble() |>
  print(n = Inf) 

## b) Combining both of the spreadsheets, making it spatial, and creating time long
Pre_V1_Giveaway_Y2017_Y2024 <-
  bind_rows(Holyoke_Giveaway_Data_Y2017_Y2024, Chelsea_Giveaway_Data_Y2017_Y2024) |>
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) |>
   pivot_longer(
     cols = c(ends_with("_2017"), ends_with("_2024"))
   , names_to = c(".value", "Year_Surveyed")
   , names_pattern = "(.*)_(2017|2024)$"
  ) |>
  mutate(Time_Period = case_when(
    Year_Surveyed == "2017" ~ "Time 1"
  , Year_Surveyed == "2024" ~ "Time 2"
  , TRUE ~ NA_character_
  )) |>
  mutate(Survey_Year_Dataset = Year_Surveyed) |>
  st_transform(st_crs(Holyoke_Property_Data_Y2023)) 

```

# 4. iTree Data: Cleaning and preparing for Holyoke, MA and Chelsea, MA 
```{r Additional iTree Data for Holyoke, MA and Chelsea, MA, echo=FALSE, message=FALSE}
# 1. Making the Broadleaf and Conifers table
## a. Creating summary table of Broadleaf and Conifers for a join
Pre_Broadleaf_Conifer_Table_V1 <- 
  Pre_V1_Giveaway_Y2017_Y2024 |>
  st_drop_geometry() |>
  filter(!is.na(Broadleaf_Conifer)) |> 
  group_by(Species, Broadleaf_Conifer) |>  
  summarize(Count = n(), .groups = "drop") |> 
  arrange(Species) |>
  tidylog::select(-Count) |>
  rename(Broadleaf_Conifer = Broadleaf_Conifer)

## b. Performing some double checks
### i) Checking for duplicates
Pre_Broadleaf_Conifer_Table_V1 |>
  count(Species) |>
  filter(n > 1) # All unique

### ii) Checking which species do not have currently a partner 
Unmatched_Leaf_Species <- 
  Pre_V1_Giveaway_Y2017_Y2024 |>
  distinct(Species) |>
  anti_join(
    Pre_Broadleaf_Conifer_Table_V1 |> distinct(Species),
    by = "Species"
  ) |>
  arrange((Species))
Unmatched_Leaf_Species 

## c. Adding the additional ones
Pre_Broadleaf_Conifer_Table_V2 <- 
  tribble(
  ~Species,                      ~Broadleaf_Conifer
  , "Aesculus hippocastanum"  , "Broadleaf"                     
  , "Aesculus x carnea"       , "Broadleaf"               
  , "Amelanchier canadensis"  , "Broadleaf"                 
  , "Eucommia ulmoides"       , "Broadleaf"             
  , "Halesia monticola"       , "Broadleaf"             
  , "Malus x domestica"       , "Broadleaf"           
  , "Prunus avium"            , "Broadleaf"       
  , "Prunus persica"          , "Broadleaf"           
  , "Prunus salicina"         , "Broadleaf"           
  , "Pyrus communis"          , "Broadleaf"          
  , "Sorbus alnifolia"        , "Broadleaf"             
  , "Styrax japonicus"        , "Broadleaf"               
  , "Thuja plicata"           , "Conifer"         
  , "Ulmus parvifolia"        , "Broadleaf"             
  , "Ulmus spp."              , "Broadleaf"
  )

## d. Combining both tables for my join list
Broadleaf_Conifer_Table <-
 bind_rows(
    Pre_Broadleaf_Conifer_Table_V1
  , Pre_Broadleaf_Conifer_Table_V2
    ) |>
 rename_with(~ paste0("Ecological_", .x)
            , .cols = -any_of("Species"))

# 2. Creating the iTree Final Table
## a. Reading and renaming columns of the 
Pre_i_Tree_Table_V1 <- 
  read_excel(
    "input_data/General/Create_iTree_spp_codes_from_inventory_list.xls.xlsx"
    , sheet = "i-Tree Species List"
  ) |>
 mutate( # This is to make it mergeable
     Species = str_c(`Genus Name`, `Species Name`, sep = " ")
  ,  Species = str_to_lower(Species)
  ,  Species = str_replace(Species, "^\\w", toupper(str_sub(Species, 1, 1)))  # Ensures the first letter is capitalized
  ) |>
  rename(Height_Maturity = `Height at Maturity (feet)`
       , i_Tree_Code        = `Species Code`
       , Growth_Form        = `Growth Form`
       , Percent_Leaf_Type  = `Percent Leaf Type`
       , Leaf_Type          = `Leaf Type`
       , Growth_Rate        = `Growth Rate`
       ) 

## b. Performing some double checks
### i) Checking for duplicates
Pre_i_Tree_Table_V1 |>
  count(Species) |>
  filter(n > 1) # All unique

### ii) Checking which species do not have currently a partner 
Unmatched_iTree_Species <- 
  Pre_V1_Giveaway_Y2017_Y2024 |>
  distinct(Species) |>
  anti_join(
    Pre_i_Tree_Table_V1 |> distinct(Species),
    by = "Species"
  )
Unmatched_iTree_Species 

## c. Creating the index table on an Excel and and reading it in
Pre_i_Tree_Table_V2 <- 
  read_excel("input_data/General/i_Tree_Appendix.xls.xlsx"
           , sheet = "i-Tree Species List"
           , n_max = 19) |>
  tidylog::select(1:8)
# For note, species like Quercus x warei, Prunus x incam, Malus x domestica, & Other [genus spp.] were the only ones without any information. This is due to not being able to find a respective i-Tree value. 

## d. Merging both these trees for potential iTree analysis
i_Tree_Table <- 
  bind_rows(
    Pre_i_Tree_Table_V1
  , Pre_i_Tree_Table_V2
    ) |>
  tidylog::select(-`Genus Name`, -`Species Name`, -Synonym, -Family, -Order, -Class, -`Common Name`) |>
  rename_with(~ paste0("Ecological_", .x)
          , .cols = -any_of(c("Genus_Name","Species","i_Tree_Code")) # Trying to make these not be note selected
    )
```

# 5. Tree Giveaway Data: Merging all datasets and final cleanings for Holyoke, MA and Chelsea, MA (2017 and 2023)
```{r Final Tree Giveawy for Holyoke, MA and Chelsea, MA}
# 1. Merging all of the datasets into one | Property and Census specifically
## a) Preparing the necessary layers needed
Pre_Parcel_Data_Y2019 <- 
  bind_rows(Holyoke_Property_Data_Y2019, Chelsea_Property_Data_Y2019) |>
  tidylog::select(-Time_Period) |>
  filter(!is.na(Parcel_Unique_ID))

Pre_Parcel_Data_Y2023 <- 
  bind_rows(Holyoke_Property_Data_Y2023, Chelsea_Property_Data_Y2023) |>
  tidylog::select(-Time_Period) |>
  filter(!is.na(Parcel_Unique_ID))

Pre_Census_Data_Y2017 <- 
  bind_rows(Holyoke_CBG_Data_Y2017, Chelsea_CBG_Data_Y2017) 

Pre_Census_Data_Y2023 <- 
  bind_rows(Holyoke_CBG_Data_Y2023, Chelsea_CBG_Data_Y2023) 

## b. Calculating each giveaway and choosing the largest polygon
### i) Finding for parcels, which is more challenging since not all are within
#### 2019, Finding all that joined
Pre_Giveaways_Parcel_Data_Y2019 <- 
  Pre_V1_Giveaway_Y2017_Y2024 |>
  filter(Time_Period == "Time 1") |>
  st_join(Pre_Parcel_Data_Y2019, left = TRUE, largest = TRUE)

#### 2019, Finding all within
Within_Giveaways_Parcel_Data_Y2019 <-
  Pre_Giveaways_Parcel_Data_Y2019 |>
  filter(!is.na(Parcel_Property_ID)) |>
  st_drop_geometry() |>
  tidylog::select(City, Time_Period, Unique_ID, starts_with("Parcel"))

#### 2019, Finding all missing points
Missing_Giveaways_Parcel_Data_Y2019 <- 
  Pre_Giveaways_Parcel_Data_Y2019 |>
  filter(is.na(Parcel_Property_ID))

#### 2019, Finding nearest parcel for missing points
Nearest_Indexes_Y2019 <- 
  Missing_Giveaways_Parcel_Data_Y2019 |>
  st_nearest_feature(Pre_Parcel_Data_Y2019)

#### 2019, Combine IDs with nearest parcel attributes
Nearest_Giveaways_Parcel_Data_Y2019 <- 
  Pre_Parcel_Data_Y2019 |> 
  st_drop_geometry() |>                                      
  slice(Nearest_Indexes_Y2019) |> # Selecting based on the closest parcels
  tidylog::select(starts_with("Parcel")) |>                   
  bind_cols(
    Missing_Giveaways_Parcel_Data_Y2019 |> 
      st_drop_geometry() |> 
      tidylog::select(City, Time_Period, Unique_ID) 
  )

#### 2019, Merging the Dataset
Giveaway_Parcel_Data_Y2019 <- 
  bind_rows(Within_Giveaways_Parcel_Data_Y2019
          , Nearest_Giveaways_Parcel_Data_Y2019)

#### 2023, Finding all that joined
Pre_Giveaways_Parcel_Data_Y2023 <- 
  Pre_V1_Giveaway_Y2017_Y2024 |>
  filter(Time_Period == "Time 2") |>
  st_join(Pre_Parcel_Data_Y2023, left = TRUE, largest = TRUE)

#### 2023, Finding all within
Within_Giveaways_Parcel_Data_Y2023 <-
  Pre_Giveaways_Parcel_Data_Y2023 |>
  filter(!is.na(Parcel_Property_ID)) |>
  st_drop_geometry() |>
  tidylog::select(City, Time_Period, Unique_ID, starts_with("Parcel"))

#### 2023, Finding all missing points
Missing_Giveaways_Parcel_Data_Y2023 <- 
  Pre_Giveaways_Parcel_Data_Y2023 |>
  filter(is.na(Parcel_Property_ID))

#### 2023, Finding nearest parcel for missing points
Nearest_Indexes_Y2023 <- 
  Missing_Giveaways_Parcel_Data_Y2023 |>
  st_nearest_feature(Pre_Parcel_Data_Y2023)

#### 2023, Combine IDs with nearest parcel attributes
Nearest_Giveaways_Parcel_Data_Y2023 <- 
  Pre_Parcel_Data_Y2023 |> 
  st_drop_geometry() |>                                      
  slice(Nearest_Indexes_Y2023) |> # Selecting based on the closest parcels
  tidylog::select(starts_with("Parcel")) |>                   
  bind_cols(
    Missing_Giveaways_Parcel_Data_Y2023 |> 
      st_drop_geometry() |> 
      tidylog::select(City, Time_Period, Unique_ID) 
  )

#### 2023, Merging the Dataset
Giveaway_Parcel_Data_Y2023 <- 
  bind_rows(Within_Giveaways_Parcel_Data_Y2023
          , Nearest_Giveaways_Parcel_Data_Y2023)

### i) Finding for census
Giveaway_Census_Data_Y2017 <- 
  Pre_V1_Giveaway_Y2017_Y2024 |> 
  mutate(Temp_Row_ID = row_number()) |>
  filter(Time_Period == "Time 1") |> 
  st_join(Pre_Census_Data_Y2017, left = TRUE, largest = TRUE) |> # Selecting the largest
  st_drop_geometry() |>
  tidylog::select(City, Time_Period, Unique_ID, starts_with("Census"))

Giveaway_Census_Data_Y2023 <- 
  Pre_V1_Giveaway_Y2017_Y2024 |> 
  mutate(Temp_Row_ID = row_number()) |>
  filter(Time_Period == "Time 2") |> 
  st_join(Pre_Census_Data_Y2023, left = TRUE, largest = TRUE) |> # Selecting the largest
  st_drop_geometry() |>
  tidylog::select(City, Time_Period, Unique_ID, starts_with("Census"))

## c. Merging the columns based on theme
Giveaway_Parcel_Data_Y2019_Y2023 <-
  bind_rows(Giveaway_Parcel_Data_Y2019, Giveaway_Parcel_Data_Y2023)

Giveaway_Census_Data_Y2017_Y2024 <-
  bind_rows(Giveaway_Census_Data_Y2017, Giveaway_Census_Data_Y2023)

## d. Combining all of the them together and some significant cleaning
Pre_V2_Giveaway_Y2017_Y2024 <-
  Pre_V1_Giveaway_Y2017_Y2024 |>
  left_join(Giveaway_Parcel_Data_Y2019_Y2023, by = c("City", "Time_Period", "Unique_ID")) |>
  left_join(Giveaway_Census_Data_Y2017_Y2024, by = c("City", "Time_Period", "Unique_ID")) 

# 2. Cleaning the final dataset for its final preparation
Pre_V3_Giveaway_Y2017_Y2024 <-
  Pre_V2_Giveaway_Y2017_Y2024 |>
  mutate(Address = str_to_upper(Address)
       , Public_Private = str_to_title(Public_Private)) |> #Making all the addresses capitals
  arrange(City, Address) |>
  # mutate(Date_Planted = if_else(is.na(Date_Planted), as.Date("2021-05-19"), Date_Planted)) |>
  mutate(
    Year_Planted = year(Date_Planted),
    Month = month(Date_Planted),
    Season_Planted = case_when(
      Month %in% c(3, 4, 5, 6, 7) ~ "SPRING" #EM: Still need to check with John Rogan 
    , Month %in% c(8, 9, 10, 11) ~ "FALL" 
    , TRUE ~ NA_character_      
    )
  ) |>
  tidylog::select(-Month, -Broadleaf_Conifer) |>
  mutate(
       , Basal_Sprouts = case_when(
            Basal_Sprouts %in% c("No","N") ~ "No"
          , Basal_Sprouts %in% c("Yes", "Yes", "1","2","3","5") ~ "Yes"
          , TRUE ~ Basal_Sprouts )# Assuming number means presence
       , DBH = ifelse(137.00, NA, DBH) # Checked for outliers and days_in_ground; the ones that were high >8 seemed reasonable given the data set
       , Height = Height # Unsure how to check these; seems fine overall again
       , Width = Width # DL: This one seems more odd; can there be 30-40 feet crown width for trees given the maximum ten years (that seems way to high)? 
       , Vigor = as.character(Vigor)
       , Vigor = case_when(
            Vigor == "1" ~ "100% to 90% Full"
          , Vigor == "2" ~ "90% to 75% Full"
          , Vigor == "3" ~ "75% to 50% Full"
          , Vigor %in% c("4","5") ~ "50% or less" #EM: 5â€”Seems to be only in Y2017 (~70) and seems to be a further subset of bad conditions so will group there. Should double check though
          , TRUE ~ NA_character_) #approx. 6 other counts of other numbers from 2017 & 0 serves the same purpose s NA_character_ so making everything else NA
       , Site_Type = case_when(
            Site_Type == "SC" ~ "Sidewalk Cutout"
          , Site_Type == "BY" ~ "Backyard"
          , Site_Type == "FY" ~ "Front Yard"
          , Site_Type == "OM" ~ "Other Maintained"
          , Site_Type == "SY" ~ "Side Yard"
          , Site_Type == "MP" ~ "Maintained Park"
          , Site_Type == "SP" ~ "Sidewalk Planting Strip"
          , TRUE ~ Site_Type)
       , Mortality_Status = case_when(
            Mortality_Status == "SD" ~ "Standing Dead"
          , Mortality_Status == "A" ~ "Alive"
          , Mortality_Status == "R" ~ "Removed"
          , Mortality_Status == "Y" ~ NA_character_ #EM: Please check, not sure what this means
          , Mortality_Status == "Unknown" ~ NA_character_
          , TRUE ~ Mortality_Status 
       )
       , Land_Use = case_when(
            Land_Use == "MFR"   ~ "Multi-Family Residential"               
          , Land_Use == "SFR-D" ~ "Single-Family Detached"               
          , Land_Use == "SFR-A" ~ "Single-Family Attached"   
          , Land_Use == "SFR"   ~ "Single-Family General"
          , Land_Use == "INST"  ~ "Institutional"               
          , Land_Use == "COMM"  ~ "Commercial"               
          , Land_Use == "MP"    ~ "Maintained Park"               
          , Land_Use == "V"     ~ "Vacant"      
          , Land_Use == "MX"    ~ "Mixed Use"            
          , Land_Use == "IND"   ~ "Industrial"              
          , Land_Use == "O"     ~ "Other"            
          , Land_Use == "TR"    ~ "Transportation"               
          , Land_Use == "UT"    ~ "Unsure" #EM: Please fix this when push comes to shove
          , TRUE ~ Land_Use)
        , General_Location = case_when(
            Site_Type %in% c("Sidewalk Cutout", "Sidewalk Planting Strip") ~ "Street Trees"
          , Site_Type %in% c("Backyard", "Front Yard", "Side Yard") ~ "Yard Trees"
          , Site_Type %in% c("Other Maintained", "Maintained Park") ~ "Maintained Area"
          , TRUE ~ NA_character_)
              ) |>
         mutate(
          General_Site_Type = case_when(
            Site_Type %in% c("Sidewalk Cutout", "Sidewalk Planting Strip") ~ "Street Trees"
          , Site_Type %in% c("Back Yard", "Backyard", "Side Yard", "Front Yard") ~ "Yard Trees"
          , Site_Type %in% c("Other Maintained", "Maintained Park") ~ "Maintained Area"
          , TRUE ~ NA_character_)
       , Research_Site_Type = case_when(
            Site_Type %in% c("Sidewalk Cutout", "Sidewalk Planting Strip") & 
            Land_Use %in% c("Single-Family Detached", "Single-Family General", "Single-Family Attached") ~ "Residential Right-of-Way" #Excluded multifamily since that may differ too greatly
          , TRUE ~ Site_Type
          )
        ) |>
    left_join(Broadleaf_Conifer_Table, by = "Species") |>
    left_join(i_Tree_Table, by = "Species")
# All now is the final step of the ground and then done :)

# 3. Calculating Days in Ground for All Data
Giveaway_Survival_Data <- 
  Pre_V3_Giveaway_Y2017_Y2024 |>
   # filter(Site_Type == c("Backyard", "Front Yard")) |>
  st_drop_geometry() |>
  tidylog::select(City, Unique_ID, Date_Planted, Time_Period, Date_Surveyed, Mortality_Status) |>
  pivot_wider(
    id_cols     = c(City, Unique_ID, Date_Planted)
  , names_from  = Time_Period          
  , values_from = c(Date_Surveyed, Mortality_Status)
  , names_sep   = "_"
  ) |>
  rename(
     Date_Surveyed_Time_1     = `Date_Surveyed_Time 1`  
   , Date_Surveyed_Time_2     = `Date_Surveyed_Time 2`   
   , Mortality_Status_Time_1  = `Mortality_Status_Time 1`
   , Mortality_Status_Time_2  = `Mortality_Status_Time 2`
  ) |>
  filter(!(is.na(Mortality_Status_Time_1) & is.na(Mortality_Status_Time_2)))|> #The issue is this;for some reason, there are present survey dates in the dataset for 2024 that have had no mortality_status taken in either T1 or T2. Because my analysis does not flag NA_, only death events and assumes everything is living otherwise, this is causing significant issues later down in the road when I subset the dataset to only look for T1 Dead | T1 Alive, T2 Dead | T2 Alive
  # Flag for when to stop counting for the days
  mutate(
    Dead_Time_1 = Mortality_Status_Time_1 %in% c("Standing Dead", "Removed", "Stump")
  , Dead_Time_2 = Mortality_Status_Time_2 %in% c("Standing Dead", "Removed", "Stump")
  # Selecting the day to stop counting
  , Inspection_Date = case_when(
      Dead_Time_1 ~ Date_Surveyed_Time_1 #Dead in 2017, Stop 2017
    , !Dead_Time_1 & Dead_Time_2 ~ Date_Surveyed_Time_2 #Alive in 2017, Dead in 2024, Stop 2024
    , TRUE ~ coalesce(Date_Surveyed_Time_2, Date_Surveyed_Time_1)
    )) |>
    filter(!is.na(Inspection_Date)) |>
  mutate(
  , Days_In_Ground = as.integer(Inspection_Date - Date_Planted) # Calculating based off of the rules set in inspection date
  # The following is for the survival analysis
  , Status = case_when(  
      Dead_Time_1 ~ 1
    , !Dead_Time_1 & Dead_Time_2 ~ 1
    , TRUE ~ 0
    )
  # Tells us when the date stopped
  , Inspection = case_when(
       Dead_Time_1 ~ 1
     , !Dead_Time_1 & Dead_Time_2 ~ 2
     , TRUE ~ if_else(!is.na(Date_Surveyed_Time_2), 2, 1)
    )
  ) |>
  mutate( # Need this for later analysis
    Has_T1_Observation = !is.na(Mortality_Status_Time_1) # has mortality status presence
  , Has_T2_Observation = !is.na(Mortality_Status_Time_2)
  ) |>
  filter(!is.na(Days_In_Ground), Days_In_Ground >= 0) |>
  filter(Inspection_Date < ymd("2025-07-01")) |>
  tidylog::select(City, Unique_ID, Days_In_Ground, Status, Inspection, Inspection_Date, Has_T1_Observation, Has_T2_Observation) |>
  rename_with(
        ~ paste0("Survival_", .x)
      , .cols = !any_of(c("City", "Unique_ID"))
    )

# 4. Creating the final dataset for its final preparation
Final_Giveaway_Y2017_Y2024 <-
  Pre_V3_Giveaway_Y2017_Y2024 |>
  left_join(Giveaway_Survival_Data, by = c("City","Unique_ID")) |>
  #--# Changes made to make sure we are having differences in the values
  mutate(
      Date_Surveyed = case_when(
        Time_Period == "Time 1" & !is.na(Date_Planted) & Date_Planted > lubridate::as_date("2017-06-27") ~ NA_Date_
      , Time_Period == "Time 1" & Survival_Status == 0 & Survival_Inspection == 2 & Date_Planted < lubridate::as_date("2017-05-30") ~ Chelsea_Median_Survey_Y2017
      , TRUE ~ Date_Surveyed
    )) |>
  mutate(
    Survival_Days_In_Ground = case_when(
       Time_Period == "Time 2" & Survival_Status == 1 & Survival_Inspection == 1 ~ NA_integer_
     , Time_Period == "Time 1" & Date_Planted > lubridate::as_date("2017-05-30") ~ NA_integer_
     , !is.na(Date_Surveyed) & !is.na(Date_Planted) ~ as.integer(Date_Surveyed - Date_Planted)
     , TRUE ~ Survival_Days_In_Ground
    )
  ) |>
#---#
  tidylog::select(
  Unique_ID                                
, City                                         
, Address                                      
, Time_Period                                  
, Date_Planted                                 
, Year_Planted                                 
, Season_Planted                               
, Year_Surveyed                                
, Date_Surveyed                                
, Family                                       
, Genus                                        
, Species                                      
, Cultivar                                     
, Common_Name                                  
, i_Tree_Code                       
, Native_Status                                
, Deciduous_Evergreen                          
, Public_Private                               
# , Comment_General                              
# , Easting                                      
# , Northing                                     
# , General_Location                             
, Land_Use                                     
, Site_Type     
, General_Site_Type
, Research_Site_Type
, Vigor                                        
, Mortality_Status                             
, Conditions                                   
, DBH
, Height
# , Width                                        
, Basal_Sprouts
# , Days_Since_Planted  #Not needed anymore                          
# , Comment_Survey                               
, Survey_Year_Dataset                          
, Parcel_Year_Dataset                          
, Parcel_Location_ID                           
# , Parcel_Unique_ID                             
# , Parcel_Property_ID                           
, Ecological_Broadleaf_Conifer                 
, Ecological_Growth_Form                       
, Ecological_Percent_Leaf_Type                 
, Ecological_Leaf_Type                         
, Ecological_Growth_Rate                       
, Ecological_Longevity                         
, Ecological_Height_Maturity                   
, Parcel_Lot_Date                              
, Parcel_Lot_Size                              
# , Parcel_Lot_Units                             
, Parcel_Lot_Price               
, Parcel_Building_Value          
, Parcel_Land_Value              
, Parcel_Other_Value             
, Parcel_Total_Value             
, Parcel_Year                                  
, Parcel_Style                                 
, Parcel_Use_Code                              
, Parcel_Zoning                                
, Parcel_Year_Built                            
, Parcel_Building_Area                         
, Parcel_Residential_Area                      
, Parcel_Units                                 
, Parcel_Number_Rooms                          
, Parcel_Stories                               
, Census_GEOID                                 
, Census_Block                                 
, Census_Tract                                 
, Census_County                                
, Census_State                                 
, Census_Median_Household_Income 
, Census_Total_Population                      
, Census_Households       
, Census_Ethnicity_Population
, Census_White_Alone                           
, Census_Black_Alone                           
, Census_American_Indian_Alone                 
, Census_Asian_Alone                           
, Census_Native_Hawaiian_Alone                 
, Census_Other_Alone                           
, Census_Two_or_More_Alone                     
, Census_Hispanic_Alone                        
, Census_White_Alone_Percentage           
, Census_Black_Alone_Percentage           
, Census_American_Indian_Alone_Percentage 
, Census_Asian_Alone_Percentage           
, Census_Native_Hawaiian_Alone_Percentage 
, Census_Other_Alone_Percentage          
, Census_Two_or_More_Alone_Percentage     
, Census_Hispanic_Alone_Percentage   
, Census_Poverty_Population
, Census_Below_Poverty
, Census_Below_Poverty_Percentage
, Census_Labor_Population 
, Census_Unemployed      
, Census_Unemployed_Percentage
, Census_Median_Age                            
, Census_Total_Population_Over_25              
, Census_Median_Gross_Rent                     
, Census_Median_Home_Value  
, Census_Tenure_Population
, Census_Owner_Occupied                        
, Census_Renter_Occupied   
, Census_Owner_Occupied_Percentage                       
, Census_Renter_Occupied_Percentage
, Census_Percentage_At_Least_High_School       
, Census_Percentage_At_Least_College           
, Survival_Days_In_Ground                      
, Survival_Status                              
, Survival_Inspection                          
, Survival_Inspection_Date  
, Survival_Has_T1_Observation
, Survival_Has_T2_Observation
, geometry
  ) |>
  rename(Census_GeoID = Census_GEOID) |>
  mutate(
    Year_Planted = as.integer(Year_Planted)
  , Year_Surveyed = as.integer(Year_Surveyed)
  , Parcel_Year = as.integer(Parcel_Year)
  , Survey_Year_Dataset = as.integer(Survey_Year_Dataset)
  , Parcel_Year_Dataset  = as.integer(Parcel_Year_Dataset)
  ) |>
  mutate(Identifier = paste0(City, "_", Unique_ID)) |>
  rename(Ecological_Native_Status = Native_Status
        , Ecological_Deciduous_Evergreen = Deciduous_Evergreen) |>
  tidylog::select(105, 1:104)


Final_Giveaway_Y2017_Y2024 |>
st_write(paste0("input_data/Final_Giveaway_Y2017_Y2024_", Sys.Date(), ".gpkg")) # Changed it to have the sys.date
```

# 6. Double Checks: Ensuring the datasets merged correctly for Holyoke, MA and Chelsea, MA (2017 and 2023) 
## a) Double checking correct dates and other issues
```{r}
# 1. Number of Rows Per Trees | Should be 2
Final_Giveaway_Y2017_Y2024 |>
  st_drop_geometry() |>
  count(Identifier, name = "n_rows") |>
  tabyl(n_rows)
# ESM: All rows have 2, which is good!

# 2. Negative Days | An issue seen earlier
Final_Giveaway_Y2017_Y2024 |>
  st_drop_geometry() |>
  summarise(
    Count = n()
  , `Negative Days` = sum(Survival_Days_In_Ground < 0, na.rm = TRUE)
  )
# ESM: All good, no negative survival days, so that was fixed

# 3. Correct Time Days Length | Since T1 and T2 differ, making sure that T2 > T1 or T2 = T1 (those are for the ones that currently have NA and Alive in T1), unless its NA since T1 = Dead 
DC_Vector_Dead_T1 <-
  Final_Giveaway_Y2017_Y2024 |>
  filter(Time_Period == "Time 1", Survival_Status == 1, Survival_Inspection == 1) |>
  distinct(Identifier) |>
  pull(Identifier) # Pull is kinda like the unique($), but you can |> it through just for your vectoe

DC_Time_Day_T1 <-
  Final_Giveaway_Y2017_Y2024 |> 
  st_drop_geometry() |>
  tidylog::select(Identifier, Time_Period, Survival_Days_In_Ground, Survival_Status, Survival_Inspection) |>
  tidyr::pivot_wider(
    names_from  = Time_Period
  , values_from = Survival_Days_In_Ground
  ) |>
  dplyr::mutate(
    Died_at_T1 = Identifier %in% DC_Vector_Dead_T1, # Making sure to not include those
    Compliance = (Died_at_T1 & is.na(`Time 2`)) | (!is.na(`Time 1`) & !is.na(`Time 2`) & `Time 2` >= `Time 1`) | (is.na(`Time 1`) & is.na(`Time 2`)) | (is.na(`Time 1`) & !is.na(`Time 2`)) #These are all acceptable conditions as listed in the earlier description
  )

DC_Time_Day_T1 |>
  summarise(`Proportion Compliance` = mean(Compliance, na.rm = TRUE)) 
#ESM: This good, all of them are complying :)

# 4. T1 Died Must Have T2 NAs
Final_Giveaway_Y2017_Y2024 |>
  st_drop_geometry() |>
  filter(Time_Period == "Time 2", Survival_Status == 1, Survival_Inspection == 1) |>
  summarise(All_T2_NAs = all(is.na(Survival_Days_In_Ground)))
# ESM: True, so they are all NAs!

# 5. Equal Days in T1 & T2 | There should not be any
Final_Giveaway_Y2017_Y2024 |>
  st_drop_geometry() |>
  tidylog::select(Identifier, Time_Period, Survival_Days_In_Ground) |>
  pivot_wider(
    names_from  = Time_Period
  , values_from = Survival_Days_In_Ground
  ) |>
  filter(!is.na(`Time 1`), !is.na(`Time 2`), `Time 1` == `Time 2`) |>
  view() 
# ESM to DHL: This is a problem but I reviewed the issue. Basically, these trees are the ones that were never surveyed in T1 and then they were reported as dead in T2. Either one of two things happenedâ€”(A) Alive T1, Dead T2 (B) Dead T1, Dead T2 (surveyed twice). On the more usual case, they were dead in T1; however, we cannot say that because they are NAs. We have to wait for John Rogan's response to see how to treat those cases. Our options, however, if not is either (A) overestimate mortality (B) underestimate mortality (C) exclude all together, limiting statistical power. Thoughts?

# 6. Planting must happen before the survey date!
Final_Giveaway_Y2017_Y2024 |>
  filter(!is.na(Date_Planted), !is.na(Date_Surveyed), Date_Surveyed < Date_Planted) |>
  tidylog::select(Identifier, City, Time_Period, Date_Planted, Date_Surveyed, Survival_Days_In_Ground) |>
  arrange(Date_Surveyed) |>
  view()
# ESM: Doesn't seem to be any! :) That means the code earlier worked


# 7. Listed as Dead in T1 | Alive in T2 (Checking if any exists)
Dead <- c("Standing Dead","Removed","Stump") # Setting the values that are dead, like our mortality study

Final_Giveaway_Y2017_Y2024 |> 
  mutate(Dead_Status = Mortality_Status %in% Dead) |> #Give me TRUES for those that are dead
  filter(Survival_Status == 1 & !Dead_Status) |> #Tell me which ones we just calculated as ALIVE but are DEAD (based on the calc earlier before the join)
  filter(Time_Period == "Time 2") |> 
  tidylog::select(Identifier, Time_Period, Mortality_Status, Survival_Status, Survival_Inspection, Date_Planted, Date_Surveyed, Survival_Days_In_Ground) |>
  view()

#ESM to DHL: These seem to be replantings. Basically, they are sharing the same IDs as the dead trees; however, they are currently alive with the new survey but have no Days_In_Ground because they were considered Dead in T1. There are two things we can do (1) Create new IDs for them and join them to our dataset; (2) Keep them exlcuded from our dataset. Not sure if we want to exclude replantings all together, include them as separate trees. Thoughts?

# 8. Listed as Blank in T1 | Dead in T2 (Checking how many are there)
Final_Giveaway_Y2017_Y2024 |> 
  mutate(Dead_Status = Mortality_Status %in% Dead) |>
  filter(Survival_Status == 1 & !Dead_Status) |>
  filter(Time_Period == "Time 1") |>
  filter(is.na(Mortality_Status)) |> # Doesn't have a mortality, so blank
  tidylog::select(Identifier, Time_Period, Mortality_Status, Survival_Status,
         Survival_Inspection, Date_Planted, Date_Surveyed, Survival_Days_In_Ground) |>
  filter(!is.na(Survival_Days_In_Ground)) |>
  view() # Sort of the opposite, we are checking when they are considered DEAD but are calculated as Alive (based on the cal earlier before the join) | it is not that they are alive, but

# ESM to DHL: As mentioned earlier, these are the trees that seem to have blanks and are considered dead in T2 (making sure we also do not include those that have had a previous value saying they are dead). The issue here is that these are making the survival rate really high, when in reality, like mentioned earlierâ€”they likely could've died in T2. A question of what we should do moving forward now. 
```

## b) Double checking missignness with mortality
```{r}
# 1. Figuring out total missing mortality 
Final_Giveaway_Y2017_Y2024 |> 
  mutate(Mortality_Status = case_when(
    Mortality_Status %in% c("Removed","Standing Dead","Stump") ~ "Dead"
  , Mortality_Status == "Alive" ~ "Alive"
  , TRUE ~ Mortality_Status ) )|> #John: Confirm why there would be an NA; they got the planting records from the city and went to a random sub-set; did not have the human-power to go to all of them. They have the lat-long, and the species, and the date, and they weren't able to add their own data from HERO. 
  st_drop_geometry() |>
  tabyl(City, Time_Period, Mortality_Status) # This is the issue <- there are SO many NAs in 2017; checked the original data, and it has the same finding. Thus, survivorship becomes challenging to determine and gives the false sense of high survivorship rate. That is the issue currently with the data. But still, pretty interesting

# 2. Figuring out total missing mortality 
## a) Chelsea
sum(!is.na(Pre_Chelsea_Giveaways$M_17) & !is.na(Pre_Chelsea_Giveaways$M_24))

table(
  "2017" = !is.na(Pre_Chelsea_Giveaways$M_17),
  "2024" = !is.na(Pre_Chelsea_Giveaways$M_24)
) # 385 we have for Chelsea

## b) Holyoke
sum(!is.na(Pre_Holyoke_Giveaways$M_17) & !is.na(Pre_Holyoke_Giveaways$M_24))

table(
  "2017" = !is.na(Pre_Holyoke_Giveaways$M_17),
  "2024" = !is.na(Pre_Holyoke_Giveaways$M_24) 
) # 276 we have for Holyoke; weird, very small; also 7 there that never existed



```

## c) Checking Other
```{r Double Checks for Holyoke, MA and Chelsea, MA, eval=FALSE, include=FALSE}
# 1. Missingness
Final_Giveaway_Y2017_Y2024 |> 
 map(~sum(is.na(.))) |>
 bind_rows() |>
 t()

# 2. Categorical Variables
Final_Giveaway_Y2017_Y2024 |> 
  st_drop_geometry() |>
  tidylog::select(-Address) |> 
  mutate_if(is.character, as.factor) |>
  select_if(is.factor) |>
  map(~tabyl(.)) |>
  bind_rows(.id = 'var') # Some Survival missing but nothing alarmingâ€”perhaps the day of those in the days-in-ground but I think I made it  

# 3. Years Planted
Final_Giveaway_Y2017_Y2024 |> 
  mapview(zcol = 'Year_Planted')

# 4. Site Types
Final_Giveaway_Y2017_Y2024 |> 
  filter(Time_Period == "Time 2") |>
  st_drop_geometry() |> 
  tabyl(Site_Type)

# 5. Site Types | Graph
Final_Giveaway_Y2017_Y2024 |> 
  st_drop_geometry() |> 
  group_by(Site_Type, City) |> 
  count() |> 
  ggplot(aes(n, Site_Type)) +
  geom_col() +
  facet_wrap(~City) +
  theme_bw(16) +
  NULL

Pre_V1_Giveaway_Y2017_Y2024 |>
  filter(Time_Period == "Time 2") |>
  st_drop_geometry() |> 
  tabyl(Site_Type)

Pre_V1_Giveaway_Y2017_Y2024 |>
  filter(Time_Period == "Time 1") |>
  st_drop_geometry() |> 
  tabyl(Site_Type)

temp_Pre_V1_Giveaway_Y2017_Y2024 <-
  bind_rows(Holyoke_Giveaway_Data_Y2017_Y2024, Chelsea_Giveaway_Data_Y2017_Y2024) |>
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326)
```


# 7. Archived: Census and Address Code for Geopackages 
```{r echo=TRUE, Archived Data Wrangling eval=FALSE}
#------INSERT IN CHAPTER 2. CENSUS DATA | STEP 0 ------# 
# 1. Loading the list of variables from ACS of 2022
## b. Listing the 2022 variable data
Variables_ACS_Y2022 <-
  tidycensus::load_variables('acs5', year = 2022) |>
  filter(geography == "block group")

# 2. Selecting the variables of ACS of 2022
## a. Selecting the 2022 variables
My_Vars <-
  c('Median_Household_Income'               = 'B19013_001'
  , 'Total_Population'                      = 'B01003_001'
  , 'Households'                            = 'B11001_001'
  , 'Ethnicity_Population'                  = 'B03002_001'
  , 'White_Alone'                           = 'B03002_003'
  , 'Black_Alone'                           = 'B03002_004'
  , 'American_Indian_Alone'                 = 'B03002_005'
  , 'Asian_Alone'                           = 'B03002_006'
  , 'Native_Hawaiian_Alone'                 = 'B03002_007'
  , 'Other_Alone'                           = 'B03002_008'
  , 'Two_or_More_Alone'                     = 'B03002_009'
  , 'Hispanic_Alone'                        = 'B03002_012'
  , 'Poverty_Population'                    = 'B17010_001'
  , 'Below_Poverty'                         = 'B17010_002'
  , 'Labor_Population'                      = 'B23025_003' # EM: Might need double-checking
  , 'Unemployed'                            = 'B23025_005'
  , 'Median_Age'                            = 'B01002_001'
  , 'Total_Population_Over_25'              = 'B15003_001'
  , 'ed_High_School_Degree'                 = 'B15003_017'
  , 'ed_GED_Degree'                         = 'B15003_018'
  , 'ed_College_Less_1_Year'                = 'B15003_019'
  , 'ed_College_More_1_Year'                = 'B15003_020'
  , 'ed_Associate_Degree'                   = 'B15003_021'
  , 'ed_plus_Bachelor_Degree'               = 'B15003_022'
  , 'ed_plus_Master_Degree'                 = 'B15003_023'
  , 'ed_plus_Professional_Degree'           = 'B15003_024'
  , 'ed_plus_Doctorate_Degree'              = 'B15003_025'
  , 'Median_Gross_Rent'                     = 'B25064_001'
  , 'Median_Home_Value'                     = 'B25077_001' 
  , 'Tenure_Population'                     = 'B25003_001'
  , 'Owner_Occupied'                        = 'B25003_002'
  , 'Renter_Occupied'                       = 'B25003_003'
      )

# 3. Selecting the variables of ACS of 2017 & 2023
## b. Downloading the Y2022 Census Data
Massachusetts_CBG_Data_Y2022 <-
  tidycensus::get_acs(
      geography = 'block group'
    , state = 'Massachusetts'
    , variables = My_Vars           
    , year = 2022
    , geometry = TRUE
    , output = 'wide'
    , moe_level = 95
    ) |>
    tidylog::select(-dplyr::ends_with('M')) |>
    tidylog::rename_with(~ gsub('E$', '', .x), dplyr::ends_with('E')) |>
    rename(NAME = NAM) |> 
    tidyr::separate( 
        NAME
      , into = c('Block', 'Tract', 'County', 'State')
      , sep  = '; ' #
      ) |> 
    tidylog::mutate(
      Total_Population_Over_25 = dplyr::na_if(Total_Population_Over_25, 0)
    , Percentage_At_Least_High_School =
        rowSums(dplyr::across(dplyr::starts_with('ed_')), na.rm = TRUE) /
        Total_Population_Over_25
    , Percentage_At_Least_College =
        rowSums(dplyr::across(dplyr::starts_with('ed_plus')), na.rm = TRUE) /
        Total_Population_Over_25
    ) |>
    mutate(White_Alone_Percentage = (White_Alone/Ethnicity_Population)
         , Black_Alone_Percentage = (Black_Alone/Ethnicity_Population)
         , American_Indian_Alone_Percentage = (American_Indian_Alone/Ethnicity_Population)
         , Asian_Alone_Percentage = (Asian_Alone/Ethnicity_Population)
         , Native_Hawaiian_Alone_Percentage = (Native_Hawaiian_Alone/Ethnicity_Population)
         , Other_Alone_Percentage = (Other_Alone/Ethnicity_Population)
         , Two_or_More_Alone_Percentage = (Two_or_More_Alone/Ethnicity_Population)
         , Hispanic_Alone_Percentage = (Hispanic_Alone/Ethnicity_Population)
         , Below_Poverty_Percentage = (Below_Poverty/Poverty_Population)
         , Unemployed_Percentage = (Unemployed/Labor_Population)
         , Owner_Occupied_Percentage = (Owner_Occupied/Tenure_Population)
         , Renter_Occupied_Percentage = (Renter_Occupied/Tenure_Population)
         ) |>
    tidylog::select(-dplyr::starts_with('ed_')) |>
    rename_with(~ paste0("Census_", .x)
              ,  .cols = -any_of("geometry")) |>
    st_transform(crs = 26986)

### i) Writing this out 
Massachusetts_CBG_Data_Y2022 |>
  st_write("input_data/General/Massachusetts_CBG_Data_Y2022.gpkg")

#------INSERT IN CHAPTER 3. ADDRESS DATA | STEP 0 ------# 
### iv) Finding all the Addresses that Need Appending
Holyoke_Giveaway_Addresses <-
  Pre_Holyoke_Giveaway_Data_Y2017_Y2024 |>
  reverse_geocode(
    lat = Latitude
  , long = Longitude
  , method = "arcgis"
  , full_results = TRUE
  )

Holyoke_Giveaway_Addresses |> 
  st_write("input_data/Holyoke/Holyoke_Giveaway_Addresses.gpkg")

```



